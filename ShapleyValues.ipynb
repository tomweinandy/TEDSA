{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Load in data\n",
    "admissions = 'tedsa_puf_2019.csv'\n",
    "df_raw = pd.read_csv(f'../../Downloads/{admissions}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter out select rows and columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 5 columns (57 remain)\n",
      "Dropped 1,340,233 observations or 71.9% of the data (524,134 rows remain)\n"
     ]
    }
   ],
   "source": [
    "# Get count of original number of rows\n",
    "old_rows = len(df_raw)\n",
    "\n",
    "# Drop defined columns (year of admission, case id, geographic metro area, geographic division, geographic region)\n",
    "columns_to_drop = ['ADMYR', 'CASEID', 'CBSA2010', 'DIVISION', 'REGION']\n",
    "df = df_raw.drop(columns=columns_to_drop)\n",
    "print(f'Dropped {len(columns_to_drop)} columns ({len(df.columns)} remain)')\n",
    "\n",
    "# Drop values where dependent variable is unknown\n",
    "df = df[df['METHUSE'] != -9]\n",
    "\n",
    "# Only keep patients admitted with self-described use of an opioid as their primary substance use (i.e., SUB1 = 5, 6, or 7)\n",
    "df = df[df['SUB1'].between(5, 7)]\n",
    "new_rows = len(df)\n",
    "percent_change = round(100*(old_rows-new_rows)/old_rows, 1)\n",
    "print(f'Dropped {\"{:,}\".format(old_rows-new_rows)} observations or {percent_change}% of the data ({\"{:,}\".format(new_rows)} rows remain)')\n",
    "\n",
    "df = df.reset_index(drop='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Balance dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes before down-sampling: 211743 312391\n",
      "Classes after down-sampling: 211743 211743\n"
     ]
    }
   ],
   "source": [
    "# Split into two dataframes, printing result\n",
    "df_ones = df[df['METHUSE']==1]\n",
    "df_twos = df[df['METHUSE']==2]\n",
    "print('Classes before down-sampling:', len(df_ones), len(df_twos))\n",
    "\n",
    "# Sample down df_twos to the length of df_ones, printing result\n",
    "ratio = len(df_ones)/len(df_twos)\n",
    "df_twos = df_twos.sample(frac=ratio)\n",
    "print('Classes after down-sampling:', len(df_ones), len(df_twos))\n",
    "\n",
    "# Recombine and shuffle for good measure\n",
    "df = pd.concat([df_ones, df_twos], axis=0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make dataset human-readable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load in variable dictionary\n",
    "with open('VariableDictionary.txt') as file:\n",
    "    variable_dict_string = file.read()\n",
    "    variable_dict = ast.literal_eval(variable_dict_string)\n",
    "\n",
    "# Rename entries in column according to dictionary\n",
    "df2 = df.copy()\n",
    "for col, col_dict in variable_dict.items():\n",
    "    if col in df2.columns:\n",
    "        for old_value, new_value in variable_dict[col].items():\n",
    "            df2[col] = df2[col].replace(old_value, new_value)\n",
    "\n",
    "# Rename \"-9\" values as \"Unknown\"\n",
    "for col in df2.columns:\n",
    "    df2[col] = df2[col].replace(-9, 'Unknown')\n",
    "\n",
    "# Merge DETNLF (detailed not in labor force) into EMPLOY==4 (not in labor force)\n",
    "detailed_employ = []\n",
    "\n",
    "for idx, value in df2.iterrows():\n",
    "    if value['EMPLOY'] == 'NotInLaborForce':\n",
    "        if value['DETNLF'] == 'Unknown':\n",
    "            # Assign 'UnknownNotInLaborForce' if 'NotInLaborForce' and 'Unknown'\n",
    "            detailed_employ.append('UnknownNotInLaborForce')\n",
    "        else:\n",
    "            # Otherwise, assign as the DETNLF value\n",
    "            detailed_employ.append(value['DETNLF'])\n",
    "    else:\n",
    "        # Assign the EMPLOY value if not 'NotInLaborForce'\n",
    "        detailed_employ.append(value['EMPLOY'])\n",
    "\n",
    "# Add a new column for detailed employment and drop the two source columns\n",
    "df2['DETEMPLOY'] = detailed_employ\n",
    "df2 = df2.drop(columns=['EMPLOY', 'DETNLF'])\n",
    "\n",
    "# Convert dependent variable to binary integer\n",
    "df2['METHUSE'] = df2['METHUSE'].replace('MethUse', 1)\n",
    "df2['METHUSE'] = df2['METHUSE'].replace('NoMethUse', 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost and Shapley"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make machine-readable dataset (encoding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df4 = df2.copy()\n",
    "# df4 = df4.sample(frac=0.1)  # small size for testing code\n",
    "\n",
    "df4['STFIPS'] = df4['STFIPS'].astype('category').cat.codes\n",
    "df4['EDUC'] = OrdinalEncoder(categories=[['Unknown', 'Grade8OrLess', 'Grade9To11', 'Grade12OrGED', '1To3yCollege', '4yCollegePlus']]).fit_transform(df4[['EDUC']])\n",
    "df4['MARSTAT'] = df4['MARSTAT'].astype('category').cat.codes\n",
    "df4['SERVICES'] = df4['SERVICES'].astype('category').cat.codes\n",
    "df4['DETCRIM'] = df4['DETCRIM'].astype('category').cat.codes\n",
    "df4['NOPRIOR'] = OrdinalEncoder(categories=[['Unknown', '0PriorTreatments', '1PriorTreatments', '2PriorTreatments', '3PriorTreatments',\n",
    "                                            '4PriorTreatments', '5PlusPriorTreatments']]).fit_transform(df4[['NOPRIOR']])\n",
    "df4['PSOURCE'] = df4['PSOURCE'].astype('category').cat.codes\n",
    "df4['ARRESTS'] = OrdinalEncoder(categories=[['Unknown', '0Arrest', '1Arrest', '2PlusArrest']]).fit_transform(df4[['ARRESTS']])\n",
    "# df4['METHUSE'] = df4['METHUSE'].astype('category').cat.codes\n",
    "df4['PSYPROB'] = df4['PSYPROB'].astype('category').cat.codes\n",
    "df4['PREG'] = df4['PREG'].astype('category').cat.codes\n",
    "df4['GENDER'] = df4['GENDER'].astype('category').cat.codes\n",
    "df4['VET'] = df4['VET'].astype('category').cat.codes\n",
    "df4['LIVARAG'] = df4['LIVARAG'].astype('category').cat.codes\n",
    "df4['DAYWAIT'] = OrdinalEncoder(categories=[['Unknown', '0DaysWait', '1To7DaysWait', '8To14DaysWait', '15To30DaysWait',\n",
    "                                            '31PlusDaysWait']]).fit_transform(df4[['DAYWAIT']])\n",
    "df4['DSMCRIT'] = df4['DSMCRIT'].astype('category').cat.codes\n",
    "df4['AGE'] = OrdinalEncoder(categories=[['Age12To14', 'Age15To17', 'Age18To20', 'Age21To24', 'Age25To29', 'Age30To34', 'Age35To39', 'Age40To44',\n",
    "                                        'Age45To49', 'Age50To54', 'Age55To64', 'Age65Plus' ]]).fit_transform(df4[['AGE']])\n",
    "df4['RACE'] = df4['RACE'].astype('category').cat.codes\n",
    "df4['ETHNIC'] = df4['ETHNIC'].astype('category').cat.codes\n",
    "df4['PRIMINC'] = df4['PRIMINC'].astype('category').cat.codes\n",
    "df4['SUB1'] = df4['SUB1'].astype('category').cat.codes\n",
    "df4['SUB2'] = df4['SUB2'].astype('category').cat.codes\n",
    "df4['SUB3'] = df4['SUB3'].astype('category').cat.codes\n",
    "df4['ROUTE1'] = df4['ROUTE1'].astype('category').cat.codes\n",
    "df4['ROUTE2'] = df4['ROUTE2'].astype('category').cat.codes\n",
    "df4['ROUTE3'] = df4['ROUTE3'].astype('category').cat.codes\n",
    "df4['FREQ1'] = OrdinalEncoder(categories=[['Unknown', 'NoUsePastMonth', 'SomeUse', 'DailyUse']]).fit_transform(df4[['FREQ1']])\n",
    "df4['FREQ2'] = OrdinalEncoder(categories=[['Unknown', 'NoUsePastMonth', 'SomeUse', 'DailyUse']]).fit_transform(df4[['FREQ2']])\n",
    "df4['FREQ3'] = OrdinalEncoder(categories=[['Unknown', 'NoUsePastMonth', 'SomeUse', 'DailyUse']]).fit_transform(df4[['FREQ3']])\n",
    "df4['FRSTUSE1'] = OrdinalEncoder(categories=[['Unknown', '11yLess', '12To14y', '15To17y', '18To20y', '21To24y', '25To29y',\n",
    "                                             '30yPlus']]).fit_transform(df4[['FRSTUSE1']])\n",
    "df4['FRSTUSE2'] = OrdinalEncoder(categories=[['Unknown', '11yLess', '12To14y', '15To17y', '18To20y', '21To24y', '25To29y',\n",
    "                                             '30yPlus']]).fit_transform(df4[['FRSTUSE2']])\n",
    "df4['FRSTUSE3'] = OrdinalEncoder(categories=[['Unknown', '11yLess', '12To14y', '15To17y', '18To20y', '21To24y', '25To29y',\n",
    "                                             '30yPlus']]).fit_transform(df4[['FRSTUSE3']])\n",
    "df4['HLTHINS'] = df4['HLTHINS'].astype('category').cat.codes\n",
    "df4['PRIMPAY'] = df4['PRIMPAY'].astype('category').cat.codes\n",
    "df4['FREQ_ATND_SELF_HELP'] = OrdinalEncoder(categories=[['Unknown', 'NoAttendance', 'SomeAttendance', '1To3TimesPastMonth', '4To7TimesPastMonth',\n",
    "                                                        '8To30TimesPastMonth']]).fit_transform(df4[['FREQ_ATND_SELF_HELP']])\n",
    "df4['ALCFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['ALCFLG']])\n",
    "df4['COKEFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['COKEFLG']])\n",
    "df4['MARFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['MARFLG']])\n",
    "df4['HERFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['HERFLG']])\n",
    "df4['METHFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['METHFLG']])\n",
    "df4['OPSYNFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['OPSYNFLG']])\n",
    "df4['PCPFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['PCPFLG']])\n",
    "df4['HALLFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['HALLFLG']])\n",
    "df4['MTHAMFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['MTHAMFLG']])\n",
    "df4['AMPHFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['AMPHFLG']])\n",
    "df4['STIMFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['STIMFLG']])\n",
    "df4['BENZFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['BENZFLG']])\n",
    "df4['TRNQFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['TRNQFLG']])\n",
    "df4['BARBFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['BARBFLG']])\n",
    "df4['SEDHPFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['SEDHPFLG']])\n",
    "df4['INHFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['INHFLG']])\n",
    "df4['OTCFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['OTCFLG']])\n",
    "df4['OTHERFLG'] = OrdinalEncoder(categories=[['NotReported', 'Reported']]).fit_transform(df4[['OTHERFLG']])\n",
    "# df4['DIVISION'] = df4['DIVISION'].astype('category').cat.codes\n",
    "# df4['REGION'] = df4['REGION'].astype('category').cat.codes\n",
    "df4['IDU'] = OrdinalEncoder(categories=[['NoIDU', 'IDU']]).fit_transform(df4[['IDU']])\n",
    "df4['ALCDRUG'] = OrdinalEncoder(categories=[['OtherDrugs', 'AlcoholAndDrugs']]).fit_transform(df4[['ALCDRUG']])\n",
    "df4['DETEMPLOY'] = df4['DETEMPLOY'].astype('category').cat.codes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train XG Boost model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X = df4.drop('METHUSE', axis=1)\n",
    "y = df4['METHUSE'].astype('float')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "# Search the parameter grid\n",
    "# Docs: https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "# https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning/notebook#2.-XGBoost-hyperparameters-\n",
    "defined_space={'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "       'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "       'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "       'learning_rate': hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "       'max_depth': hp.quniform(\"max_depth\", 3, 27, 1),\n",
    "       'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "       'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n",
    "       'reg_alpha' : hp.quniform('reg_alpha', 40, 180, 1),\n",
    "       'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "       'subsample': hp.quniform('subsample', 0.5, 1, 0.05)\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    clf = xgb.XGBClassifier(colsample_bytree=round(space['colsample_bytree'], 0),\n",
    "                          early_stopping_rounds=10,\n",
    "                          eta=space['eta'],\n",
    "                          eval_metric='auc',\n",
    "                          gamma=space['gamma'],\n",
    "                          learning_rate=space['learning_rate'],\n",
    "                          max_depth=int(round(space['max_depth'], 0)),\n",
    "                          min_child_weight=space['min_child_weight'],\n",
    "                          n_estimators=space['n_estimators'],\n",
    "                          objective='binary:logistic',\n",
    "                          reg_alpha=space['reg_alpha'],\n",
    "                          reg_lambda=space['reg_lambda'],\n",
    "                          seed=24,\n",
    "                          subsample=round(space['subsample'], 0))\n",
    "\n",
    "    # Evaluate the model and record performance metrics\n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    clf.fit(X_train, y_train, eval_set=evaluation, verbose=False)\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    y_pred = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test,y_pred)\n",
    "\n",
    "    print (f\"Accuracy: {round(accuracy, 4)}, AUC: {round(auc, 4)}\")\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6836 AUC: 0.7426                           \n",
      "Accuracy: 0.8524 AUC: 0.9354                                                      \n",
      "Accuracy: 0.7345 AUC: 0.8138                                                         \n",
      "Accuracy: 0.7292 AUC: 0.808                                                          \n",
      "Accuracy: 0.8399 AUC: 0.925                                                          \n",
      "Accuracy: 0.8427 AUC: 0.9276                                                          \n",
      "Accuracy: 0.7412 AUC: 0.8243                                                          \n",
      "Accuracy: 0.7177 AUC: 0.7932                                                          \n",
      "Accuracy: 0.8417 AUC: 0.9274                                                         \n",
      "Accuracy: 0.8505 AUC: 0.9336                                                         \n",
      "Accuracy: 0.7347 AUC: 0.8142                                                          \n",
      "Accuracy: 0.7351 AUC: 0.8189                                                          \n",
      "Accuracy: 0.8386 AUC: 0.9244                                                          \n",
      "Accuracy: 0.5011 AUC: 0.5                                                             \n",
      "Accuracy: 0.851 AUC: 0.9343                                                           \n",
      "Accuracy: 0.727 AUC: 0.8056                                                           \n",
      "Accuracy: 0.7269 AUC: 0.806                                                           \n",
      "Accuracy: 0.8528 AUC: 0.9351                                                          \n",
      "Accuracy: 0.8451 AUC: 0.9291                                                           \n",
      "Accuracy: 0.7323 AUC: 0.8115                                                           \n",
      "Accuracy: 0.8529 AUC: 0.9357                                                           \n",
      "Accuracy: 0.8474 AUC: 0.9313                                                            \n",
      "Accuracy: 0.8469 AUC: 0.9307                                                            \n",
      "Accuracy: 0.8464 AUC: 0.931                                                             \n",
      "Accuracy: 0.8398 AUC: 0.9247                                                            \n",
      "Accuracy: 0.8508 AUC: 0.9338                                                            \n",
      "Accuracy: 0.8479 AUC: 0.9313                                                            \n",
      "Accuracy: 0.8396 AUC: 0.9244                                                            \n",
      "Accuracy: 0.8474 AUC: 0.931                                                             \n",
      "Accuracy: 0.8487 AUC: 0.9321                                                            \n",
      "Accuracy: 0.8519 AUC: 0.9342                                                            \n",
      "Accuracy: 0.8523 AUC: 0.9354                                                            \n",
      "Accuracy: 0.8463 AUC: 0.93                                                              \n",
      "Accuracy: 0.8505 AUC: 0.9339                                                            \n",
      "Accuracy: 0.8474 AUC: 0.9308                                                            \n",
      "Accuracy: 0.84 AUC: 0.925                                                               \n",
      "Accuracy: 0.8508 AUC: 0.934                                                             \n",
      "Accuracy: 0.8458 AUC: 0.9292                                                            \n",
      "Accuracy: 0.8527 AUC: 0.9358                                                            \n",
      "Accuracy: 0.8376 AUC: 0.9238                                                            \n",
      "Accuracy: 0.7362 AUC: 0.8152                                                            \n",
      "Accuracy: 0.8458 AUC: 0.9301                                                            \n",
      "Accuracy: 0.8405 AUC: 0.9259                                                            \n",
      "Accuracy: 0.8475 AUC: 0.9314                                                            \n",
      "Accuracy: 0.8367 AUC: 0.9231                                                            \n",
      "Accuracy: 0.8462 AUC: 0.9306                                                            \n",
      "Accuracy: 0.8407 AUC: 0.9263                                                            \n",
      "Accuracy: 0.8525 AUC: 0.9355                                                            \n",
      "Accuracy: 0.8444 AUC: 0.9288                                                            \n",
      "Accuracy: 0.7356 AUC: 0.8148                                                            \n",
      "Accuracy: 0.8493 AUC: 0.9322                                                            \n",
      "Accuracy: 0.8387 AUC: 0.9237                                                            \n",
      "Accuracy: 0.7418 AUC: 0.8249                                                            \n",
      "Accuracy: 0.8446 AUC: 0.9299                                                            \n",
      "Accuracy: 0.5011 AUC: 0.5                                                              \n",
      "Accuracy: 0.8397 AUC: 0.9248                                                           \n",
      "Accuracy: 0.8474 AUC: 0.9305                                                         \n",
      "Accuracy: 0.8523 AUC: 0.935                                                            \n",
      "Accuracy: 0.8392 AUC: 0.9248                                                            \n",
      "Accuracy: 0.7229 AUC: 0.8004                                                            \n",
      "Accuracy: 0.852 AUC: 0.9354                                                             \n",
      "Accuracy: 0.8486 AUC: 0.9316                                                            \n",
      "Accuracy: 0.8414 AUC: 0.9259                                                            \n",
      "Accuracy: 0.7328 AUC: 0.8122                                                            \n",
      "Accuracy: 0.8519 AUC: 0.9344                                                            \n",
      "Accuracy: 0.8526 AUC: 0.9361                                                            \n",
      "Accuracy: 0.8519 AUC: 0.9355                                                            \n",
      "Accuracy: 0.8517 AUC: 0.9348                                                            \n",
      "Accuracy: 0.8516 AUC: 0.9354                                                            \n",
      "Accuracy: 0.8493 AUC: 0.9327                                                            \n",
      "Accuracy: 0.85 AUC: 0.934                                                               \n",
      "Accuracy: 0.8478 AUC: 0.9316                                                            \n",
      "Accuracy: 0.8505 AUC: 0.9335                                                            \n",
      "Accuracy: 0.8469 AUC: 0.9307                                                            \n",
      "Accuracy: 0.8492 AUC: 0.9328                                                            \n",
      "Accuracy: 0.8525 AUC: 0.9353                                                            \n",
      "Accuracy: 0.8426 AUC: 0.9274                                                            \n",
      "Accuracy: 0.8425 AUC: 0.9276                                                            \n",
      "Accuracy: 0.852 AUC: 0.9345                                                           \n",
      "Accuracy: 0.8502 AUC: 0.933                                                           \n",
      "Accuracy: 0.8436 AUC: 0.9278                                                          \n",
      "Accuracy: 0.8519 AUC: 0.935                                                           \n",
      "Accuracy: 0.8456 AUC: 0.9304                                                          \n",
      "Accuracy: 0.8482 AUC: 0.9324                                                          \n",
      "Accuracy: 0.8473 AUC: 0.9313                                                          \n",
      "Accuracy: 0.8461 AUC: 0.9302                                                          \n",
      "Accuracy: 0.8483 AUC: 0.9316                                                          \n",
      "Accuracy: 0.7316 AUC: 0.8106                                                          \n",
      "Accuracy: 0.7315 AUC: 0.8106                                                          \n",
      "Accuracy: 0.8454 AUC: 0.9294                                                          \n",
      "Accuracy: 0.849 AUC: 0.9325                                                           \n",
      "Accuracy: 0.8521 AUC: 0.935                                                           \n",
      "Accuracy: 0.8406 AUC: 0.9253                                                          \n",
      "Accuracy: 0.8516 AUC: 0.9342                                                          \n",
      "Accuracy: 0.7278 AUC: 0.8067                                                          \n",
      "Accuracy: 0.8505 AUC: 0.9336                                                          \n",
      "Accuracy: 0.8433 AUC: 0.9273                                                          \n",
      "Accuracy: 0.8517 AUC: 0.9346                                                          \n",
      "Accuracy: 0.8503 AUC: 0.933                                                           \n",
      "Accuracy: 0.5011 AUC: 0.5                                                             \n",
      "100%|██████████| 100/100 [5:03:47<00:00, 182.27s/trial, best loss: -0.8529363149070817]\n"
     ]
    }
   ],
   "source": [
    "# Begin training\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = defined_space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'colsample_bytree': 0.61,\n 'eta': 0.25,\n 'gamma': 0.8,\n 'learning_rate': 0.22,\n 'max_depth': 16.0,\n 'min_child_weight': 0.0,\n 'n_estimators': 812,\n 'reg_alpha': 40.0,\n 'reg_lambda': 0.9241629285526229,\n 'subsample': 0.9}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Best from 100 runs\n",
    "\n",
    " {'colsample_bytree': 0.61,\n",
    " 'eta': 0.25,\n",
    " 'gamma': 0.8,\n",
    " 'learning_rate': 0.22,\n",
    " 'max_depth': 16.0,\n",
    " 'min_child_weight': 0.0,\n",
    " 'n_estimators': 812,\n",
    " 'reg_alpha': 40.0,\n",
    " 'reg_lambda': 0.9241629285526229,\n",
    " 'subsample': 0.9}\n",
    "\"\"\"\n",
    "\n",
    "# best_hyperparams = {'colsample_bytree': 0.61,\n",
    "#                      'eta': 0.25,\n",
    "#                      'gamma': 0.8,\n",
    "#                      'learning_rate': 0.22,\n",
    "#                      'max_depth': 16.0,\n",
    "#                      'min_child_weight': 0.0,\n",
    "#                      'n_estimators': 812,\n",
    "#                      'reg_alpha': 40.0,\n",
    "#                      'reg_lambda': 0.9241629285526229,\n",
    "#                      'subsample': 0.9}\n",
    "\n",
    "best_hyperparams"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.85,\n              early_stopping_rounds=None, enable_categorical=False, eta=0.45,\n              eval_metric='auc', gamma=0.7000000000000001, gpu_id=-1,\n              grow_policy='depthwise', importance_type=None,\n              interaction_constraints='', learning_rate=0.34, max_bin=256,\n              max_cat_to_onehot=4, max_delta_step=0, max_depth=18, max_leaves=0,\n              min_child_weight=4.0, missing=nan, monotone_constraints='()',\n              n_estimators=45, n_jobs=0, num_parallel_tree=1, predictor='auto',\n              random_state=24, reg_alpha=40.0, ...)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train best model\n",
    "best_hyperparams_formatted = best_hyperparams.copy()\n",
    "best_hyperparams_formatted['max_depth'] = int(best_hyperparams['max_depth'])\n",
    "best_hyperparams_formatted['eval_metric'] = 'auc'\n",
    "best_hyperparams_formatted['objective'] = 'binary:logistic'\n",
    "best_hyperparams_formatted['seed'] = 24\n",
    "\n",
    "best_model = xgb.XGBClassifier(**best_hyperparams_formatted)\n",
    "best_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8482, AUC: 0.9322\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and record performance metrics\n",
    "evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "best_pred = best_model.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, best_pred>0.5)\n",
    "y_best_pred = best_model.predict_proba(X_test)[:,1]\n",
    "best_auc = roc_auc_score(y_test,y_best_pred)\n",
    "\n",
    "print (f\"Accuracy: {round(best_accuracy, 4)}, AUC: {round(best_auc, 4)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interpretability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Generate Shapley values\n",
    "explainer = shap.Explainer(best_model)\n",
    "shap_values = explainer(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": ".values =\narray([[-6.14417195e-01, -1.07647009e-01, -8.96000713e-02, ...,\n        -1.23644751e-02,  6.48894254e-03,  6.44573122e-02],\n       [-4.01042178e-02, -6.68558925e-02,  8.15624669e-02, ...,\n        -7.13172629e-02,  1.12182824e-02, -2.36332673e-03],\n       [-1.22391188e+00,  3.59972045e-02,  8.33280291e-03, ...,\n         2.85950415e-02,  1.04355039e-02, -6.46168739e-03],\n       ...,\n       [ 1.51008248e-01,  1.01002909e-01, -2.31086593e-02, ...,\n         5.64009584e-02,  1.05127813e-02, -6.46924302e-02],\n       [ 3.76244895e-02, -7.54593057e-04,  8.16535205e-02, ...,\n         1.06938146e-01,  6.30442845e-03,  3.02827787e-02],\n       [ 2.36923695e-01,  1.04050718e-01,  1.64596252e-02, ...,\n        -5.35444357e-02,  8.89453478e-03, -1.31306812e-01]], dtype=float32)\n\n.base_values =\narray([-0.01637657, -0.01637657, -0.01637657, ..., -0.01637657,\n       -0.01637657, -0.01637657], dtype=float32)\n\n.data =\narray([[ 4.,  4.,  4., ...,  1.,  0.,  4.],\n       [19.,  3.,  2., ...,  0.,  0.,  4.],\n       [19.,  2.,  1., ...,  0.,  0.,  3.],\n       ...,\n       [ 4.,  3.,  4., ...,  1.,  0.,  7.],\n       [ 5.,  3.,  2., ...,  1.,  0.,  5.],\n       [19.,  2.,  1., ...,  0.,  0.,  5.]])"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values   # Can we export these values as a csv? Trying to find a way to not have to run them each time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('say \"Work complete\"')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "           feature_name  feature_importance  feature_importance_out_of_100\n0              SERVICES            1.169295                       0.221355\n1                STFIPS            0.808112                       0.152981\n2               PSOURCE            0.297946                       0.056403\n3               NOPRIOR            0.260033                       0.049226\n4               HLTHINS            0.209499                       0.039660\n5                 FREQ1            0.171629                       0.032491\n6               DSMCRIT            0.164464                       0.031134\n7   FREQ_ATND_SELF_HELP            0.139806                       0.026466\n8               PRIMINC            0.130791                       0.024760\n9               PRIMPAY            0.129681                       0.024550\n10              DAYWAIT            0.118846                       0.022498\n11                  AGE            0.105291                       0.019932\n12              PSYPROB            0.100620                       0.019048\n13              LIVARAG            0.099050                       0.018751\n14            DETEMPLOY            0.099006                       0.018742\n15                 SUB2            0.088223                       0.016701\n16             FRSTUSE1            0.079517                       0.015053\n17                 SUB3            0.075205                       0.014237\n18              ARRESTS            0.071864                       0.013604\n19                FREQ2            0.064924                       0.012290\n20              MARSTAT            0.063794                       0.012077\n21              DETCRIM            0.061273                       0.011599\n22             MTHAMFLG            0.060145                       0.011386\n23                FREQ3            0.059108                       0.011189\n24                 EDUC            0.051913                       0.009827\n25               HERFLG            0.051850                       0.009816\n26                 RACE            0.051645                       0.009777\n27                 PREG            0.051288                       0.009709\n28             FRSTUSE2            0.046171                       0.008740\n29               ROUTE3            0.043593                       0.008252\n30               ROUTE1            0.042054                       0.007961\n31                  IDU            0.038171                       0.007226\n32               ROUTE2            0.035611                       0.006741\n33             FRSTUSE3            0.035288                       0.006680\n34               MARFLG            0.033332                       0.006310\n35                 SUB1            0.028029                       0.005306\n36               ALCFLG            0.024488                       0.004636\n37               ETHNIC            0.022293                       0.004220\n38             OPSYNFLG            0.021677                       0.004104\n39               GENDER            0.021095                       0.003993\n40              COKEFLG            0.013388                       0.002534\n41              ALCDRUG            0.010694                       0.002024\n42                  VET            0.009283                       0.001757\n43              BENZFLG            0.008733                       0.001653\n44             OTHERFLG            0.003872                       0.000733\n45              METHFLG            0.003580                       0.000678\n46              STIMFLG            0.002831                       0.000536\n47              AMPHFLG            0.001696                       0.000321\n48             SEDHPFLG            0.001067                       0.000202\n49               PCPFLG            0.000306                       0.000058\n50              HALLFLG            0.000160                       0.000030\n51               OTCFLG            0.000090                       0.000017\n52              TRNQFLG            0.000058                       0.000011\n53              BARBFLG            0.000048                       0.000009\n54               INHFLG            0.000019                       0.000004",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_name</th>\n      <th>feature_importance</th>\n      <th>feature_importance_out_of_100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SERVICES</td>\n      <td>1.169295</td>\n      <td>0.221355</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>STFIPS</td>\n      <td>0.808112</td>\n      <td>0.152981</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PSOURCE</td>\n      <td>0.297946</td>\n      <td>0.056403</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NOPRIOR</td>\n      <td>0.260033</td>\n      <td>0.049226</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HLTHINS</td>\n      <td>0.209499</td>\n      <td>0.039660</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>FREQ1</td>\n      <td>0.171629</td>\n      <td>0.032491</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DSMCRIT</td>\n      <td>0.164464</td>\n      <td>0.031134</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>FREQ_ATND_SELF_HELP</td>\n      <td>0.139806</td>\n      <td>0.026466</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>PRIMINC</td>\n      <td>0.130791</td>\n      <td>0.024760</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PRIMPAY</td>\n      <td>0.129681</td>\n      <td>0.024550</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DAYWAIT</td>\n      <td>0.118846</td>\n      <td>0.022498</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>AGE</td>\n      <td>0.105291</td>\n      <td>0.019932</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>PSYPROB</td>\n      <td>0.100620</td>\n      <td>0.019048</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>LIVARAG</td>\n      <td>0.099050</td>\n      <td>0.018751</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DETEMPLOY</td>\n      <td>0.099006</td>\n      <td>0.018742</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SUB2</td>\n      <td>0.088223</td>\n      <td>0.016701</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>FRSTUSE1</td>\n      <td>0.079517</td>\n      <td>0.015053</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SUB3</td>\n      <td>0.075205</td>\n      <td>0.014237</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ARRESTS</td>\n      <td>0.071864</td>\n      <td>0.013604</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>FREQ2</td>\n      <td>0.064924</td>\n      <td>0.012290</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>MARSTAT</td>\n      <td>0.063794</td>\n      <td>0.012077</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>DETCRIM</td>\n      <td>0.061273</td>\n      <td>0.011599</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>MTHAMFLG</td>\n      <td>0.060145</td>\n      <td>0.011386</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>FREQ3</td>\n      <td>0.059108</td>\n      <td>0.011189</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>EDUC</td>\n      <td>0.051913</td>\n      <td>0.009827</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>HERFLG</td>\n      <td>0.051850</td>\n      <td>0.009816</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>RACE</td>\n      <td>0.051645</td>\n      <td>0.009777</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>PREG</td>\n      <td>0.051288</td>\n      <td>0.009709</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>FRSTUSE2</td>\n      <td>0.046171</td>\n      <td>0.008740</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>ROUTE3</td>\n      <td>0.043593</td>\n      <td>0.008252</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>ROUTE1</td>\n      <td>0.042054</td>\n      <td>0.007961</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>IDU</td>\n      <td>0.038171</td>\n      <td>0.007226</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>ROUTE2</td>\n      <td>0.035611</td>\n      <td>0.006741</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>FRSTUSE3</td>\n      <td>0.035288</td>\n      <td>0.006680</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>MARFLG</td>\n      <td>0.033332</td>\n      <td>0.006310</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>SUB1</td>\n      <td>0.028029</td>\n      <td>0.005306</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>ALCFLG</td>\n      <td>0.024488</td>\n      <td>0.004636</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>ETHNIC</td>\n      <td>0.022293</td>\n      <td>0.004220</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>OPSYNFLG</td>\n      <td>0.021677</td>\n      <td>0.004104</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>GENDER</td>\n      <td>0.021095</td>\n      <td>0.003993</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>COKEFLG</td>\n      <td>0.013388</td>\n      <td>0.002534</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>ALCDRUG</td>\n      <td>0.010694</td>\n      <td>0.002024</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>VET</td>\n      <td>0.009283</td>\n      <td>0.001757</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>BENZFLG</td>\n      <td>0.008733</td>\n      <td>0.001653</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>OTHERFLG</td>\n      <td>0.003872</td>\n      <td>0.000733</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>METHFLG</td>\n      <td>0.003580</td>\n      <td>0.000678</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>STIMFLG</td>\n      <td>0.002831</td>\n      <td>0.000536</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>AMPHFLG</td>\n      <td>0.001696</td>\n      <td>0.000321</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>SEDHPFLG</td>\n      <td>0.001067</td>\n      <td>0.000202</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>PCPFLG</td>\n      <td>0.000306</td>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>HALLFLG</td>\n      <td>0.000160</td>\n      <td>0.000030</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>OTCFLG</td>\n      <td>0.000090</td>\n      <td>0.000017</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>TRNQFLG</td>\n      <td>0.000058</td>\n      <td>0.000011</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>BARBFLG</td>\n      <td>0.000048</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>INHFLG</td>\n      <td>0.000019</td>\n      <td>0.000004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absolute_share(input_list):\n",
    "    absolute_list = [abs(i) for i in input_list]\n",
    "    absolute_share_list = [j/sum(absolute_list) for j in absolute_list]\n",
    "    return absolute_share_list\n",
    "\n",
    "# Show table of top Shapley values\n",
    "feature_names = X.columns\n",
    "result = pd.DataFrame(shap_values.values, columns=feature_names, index=X.index)\n",
    "# result.to_csv('shapley_results.csv', index=False)\n",
    "\n",
    "values = np.abs(result.values).mean(0)\n",
    "abs_values = absolute_share(np.abs(result.values).mean(0))\n",
    "shap_importance = pd.DataFrame(list(zip(feature_names, values, abs_values)), columns=['feature_name','feature_importance', 'feature_importance_out_of_100'])\n",
    "shap_importance.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n",
    "shap_importance.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "0.07963869985123616"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (-0.1199*12982 + -0.0953*13336 + 0.0634*53816 + -0.0368*4564)/(12982 + 13336 + 53816 + 4564)\n",
    "(0.1295*12982 + 0.0995*13336 + 0.0641*53816 + 0.0630*4564)/(12982 + 13336 + 53816 + 4564)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'DependLiving', 1: 'Homeless', 2: 'IndependentLiving', 3: 'Unknown'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "LIVARAG\n2    268885\n1     66100\n0     65813\n3     22688\ndtype: int64"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livarag_dict = {0:'DependLiving', 1:'Homeless', 2:'IndependentLiving', 3:'Unknown'}\n",
    "print(livarag_dict)\n",
    "X.value_counts('LIVARAG')\n",
    "# df2.value_counts('LIVARAG')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "           LIVARAG  absolute_livarag\nhomeless                            \n0        -0.128457          0.149513\n1        -0.096136          0.105528\n2         0.078390          0.079853\n3        -0.123680          0.161300",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIVARAG</th>\n      <th>absolute_livarag</th>\n    </tr>\n    <tr>\n      <th>homeless</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.128457</td>\n      <td>0.149513</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.096136</td>\n      <td>0.105528</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.078390</td>\n      <td>0.079853</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.123680</td>\n      <td>0.161300</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = pd.read_csv('shapley_results.csv')\n",
    "result_homeless = result.copy()\n",
    "result_homeless.insert(0, 'homeless', X['LIVARAG'])\n",
    "result_homeless.insert(1, 'absolute_livarag', abs(result_homeless['LIVARAG']))\n",
    "result_homeless_grouped = result_homeless.groupby('homeless').mean()[['LIVARAG', 'absolute_livarag']]\n",
    "result_homeless_var = result_homeless_grouped.iloc[1]['LIVARAG']\n",
    "result_homeless_grouped"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "     homeless_shapley  housed_shapley  difference_shapley\nAK          -0.055358        0.049442           -0.104800\nAL          -0.066609        0.033245           -0.099854\nAR          -0.045466        0.032297           -0.077763\nCA          -0.158450        0.053071           -0.211521\nCO          -0.021190        0.037794           -0.058985\nCT          -0.080023        0.032898           -0.112921\nDC          -0.116890       -0.052680           -0.064209\nDE          -0.091809        0.056383           -0.148192\nGA          -0.111057        0.001415           -0.112471\nHI          -0.098834       -0.044641           -0.054193\nIA          -0.101672        0.016359           -0.118032\nID          -0.119816        0.011914           -0.131730\nIL          -0.145256       -0.069825           -0.075430\nIN          -0.125026        0.033729           -0.158756\nKS          -0.105221        0.020748           -0.125968\nKY          -0.114899        0.052957           -0.167855\nLA          -0.106424       -0.011155           -0.095268\nMA          -0.111383        0.049222           -0.160605\nMD          -0.164024        0.081754           -0.245778\nME          -0.020471        0.067789           -0.088260\nMI          -0.100128        0.032042           -0.132170\nMN          -0.018607       -0.007261           -0.011346\nMO          -0.104886        0.054892           -0.159778\nMS          -0.054201        0.034615           -0.088817\nMT          -0.019482        0.009486           -0.028968\nNC          -0.074169        0.059643           -0.133812\nND          -0.055402        0.013377           -0.068778\nNE          -0.144916       -0.031235           -0.113682\nNH          -0.074476       -0.021811           -0.052665\nNJ          -0.114060        0.055770           -0.169830\nNM          -0.179785       -0.056526           -0.123259\nNV          -0.036247       -0.015763           -0.020484\nNY          -0.039729        0.028165           -0.067893\nOH           0.005004        0.009368           -0.004364\nOK           0.011532        0.028711           -0.017179\nPA          -0.025846       -0.055573            0.029727\nPR          -0.132558        0.041833           -0.174391\nRI          -0.028326        0.080686           -0.109013\nSC          -0.049840        0.032186           -0.082026\nSD          -0.076423        0.026519           -0.102943\nTN          -0.047003        0.015407           -0.062411\nTX          -0.161867       -0.040913           -0.120954\nUT          -0.072992        0.046660           -0.119652\nVA          -0.074930        0.023529           -0.098459\nVT          -0.058992        0.027634           -0.086625\nWI          -0.103530        0.025347           -0.128877\nWY          -0.050587        0.029160           -0.079747\nUSA         -0.096136        0.037717           -0.133853",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>homeless_shapley</th>\n      <th>housed_shapley</th>\n      <th>difference_shapley</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AK</th>\n      <td>-0.055358</td>\n      <td>0.049442</td>\n      <td>-0.104800</td>\n    </tr>\n    <tr>\n      <th>AL</th>\n      <td>-0.066609</td>\n      <td>0.033245</td>\n      <td>-0.099854</td>\n    </tr>\n    <tr>\n      <th>AR</th>\n      <td>-0.045466</td>\n      <td>0.032297</td>\n      <td>-0.077763</td>\n    </tr>\n    <tr>\n      <th>CA</th>\n      <td>-0.158450</td>\n      <td>0.053071</td>\n      <td>-0.211521</td>\n    </tr>\n    <tr>\n      <th>CO</th>\n      <td>-0.021190</td>\n      <td>0.037794</td>\n      <td>-0.058985</td>\n    </tr>\n    <tr>\n      <th>CT</th>\n      <td>-0.080023</td>\n      <td>0.032898</td>\n      <td>-0.112921</td>\n    </tr>\n    <tr>\n      <th>DC</th>\n      <td>-0.116890</td>\n      <td>-0.052680</td>\n      <td>-0.064209</td>\n    </tr>\n    <tr>\n      <th>DE</th>\n      <td>-0.091809</td>\n      <td>0.056383</td>\n      <td>-0.148192</td>\n    </tr>\n    <tr>\n      <th>GA</th>\n      <td>-0.111057</td>\n      <td>0.001415</td>\n      <td>-0.112471</td>\n    </tr>\n    <tr>\n      <th>HI</th>\n      <td>-0.098834</td>\n      <td>-0.044641</td>\n      <td>-0.054193</td>\n    </tr>\n    <tr>\n      <th>IA</th>\n      <td>-0.101672</td>\n      <td>0.016359</td>\n      <td>-0.118032</td>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <td>-0.119816</td>\n      <td>0.011914</td>\n      <td>-0.131730</td>\n    </tr>\n    <tr>\n      <th>IL</th>\n      <td>-0.145256</td>\n      <td>-0.069825</td>\n      <td>-0.075430</td>\n    </tr>\n    <tr>\n      <th>IN</th>\n      <td>-0.125026</td>\n      <td>0.033729</td>\n      <td>-0.158756</td>\n    </tr>\n    <tr>\n      <th>KS</th>\n      <td>-0.105221</td>\n      <td>0.020748</td>\n      <td>-0.125968</td>\n    </tr>\n    <tr>\n      <th>KY</th>\n      <td>-0.114899</td>\n      <td>0.052957</td>\n      <td>-0.167855</td>\n    </tr>\n    <tr>\n      <th>LA</th>\n      <td>-0.106424</td>\n      <td>-0.011155</td>\n      <td>-0.095268</td>\n    </tr>\n    <tr>\n      <th>MA</th>\n      <td>-0.111383</td>\n      <td>0.049222</td>\n      <td>-0.160605</td>\n    </tr>\n    <tr>\n      <th>MD</th>\n      <td>-0.164024</td>\n      <td>0.081754</td>\n      <td>-0.245778</td>\n    </tr>\n    <tr>\n      <th>ME</th>\n      <td>-0.020471</td>\n      <td>0.067789</td>\n      <td>-0.088260</td>\n    </tr>\n    <tr>\n      <th>MI</th>\n      <td>-0.100128</td>\n      <td>0.032042</td>\n      <td>-0.132170</td>\n    </tr>\n    <tr>\n      <th>MN</th>\n      <td>-0.018607</td>\n      <td>-0.007261</td>\n      <td>-0.011346</td>\n    </tr>\n    <tr>\n      <th>MO</th>\n      <td>-0.104886</td>\n      <td>0.054892</td>\n      <td>-0.159778</td>\n    </tr>\n    <tr>\n      <th>MS</th>\n      <td>-0.054201</td>\n      <td>0.034615</td>\n      <td>-0.088817</td>\n    </tr>\n    <tr>\n      <th>MT</th>\n      <td>-0.019482</td>\n      <td>0.009486</td>\n      <td>-0.028968</td>\n    </tr>\n    <tr>\n      <th>NC</th>\n      <td>-0.074169</td>\n      <td>0.059643</td>\n      <td>-0.133812</td>\n    </tr>\n    <tr>\n      <th>ND</th>\n      <td>-0.055402</td>\n      <td>0.013377</td>\n      <td>-0.068778</td>\n    </tr>\n    <tr>\n      <th>NE</th>\n      <td>-0.144916</td>\n      <td>-0.031235</td>\n      <td>-0.113682</td>\n    </tr>\n    <tr>\n      <th>NH</th>\n      <td>-0.074476</td>\n      <td>-0.021811</td>\n      <td>-0.052665</td>\n    </tr>\n    <tr>\n      <th>NJ</th>\n      <td>-0.114060</td>\n      <td>0.055770</td>\n      <td>-0.169830</td>\n    </tr>\n    <tr>\n      <th>NM</th>\n      <td>-0.179785</td>\n      <td>-0.056526</td>\n      <td>-0.123259</td>\n    </tr>\n    <tr>\n      <th>NV</th>\n      <td>-0.036247</td>\n      <td>-0.015763</td>\n      <td>-0.020484</td>\n    </tr>\n    <tr>\n      <th>NY</th>\n      <td>-0.039729</td>\n      <td>0.028165</td>\n      <td>-0.067893</td>\n    </tr>\n    <tr>\n      <th>OH</th>\n      <td>0.005004</td>\n      <td>0.009368</td>\n      <td>-0.004364</td>\n    </tr>\n    <tr>\n      <th>OK</th>\n      <td>0.011532</td>\n      <td>0.028711</td>\n      <td>-0.017179</td>\n    </tr>\n    <tr>\n      <th>PA</th>\n      <td>-0.025846</td>\n      <td>-0.055573</td>\n      <td>0.029727</td>\n    </tr>\n    <tr>\n      <th>PR</th>\n      <td>-0.132558</td>\n      <td>0.041833</td>\n      <td>-0.174391</td>\n    </tr>\n    <tr>\n      <th>RI</th>\n      <td>-0.028326</td>\n      <td>0.080686</td>\n      <td>-0.109013</td>\n    </tr>\n    <tr>\n      <th>SC</th>\n      <td>-0.049840</td>\n      <td>0.032186</td>\n      <td>-0.082026</td>\n    </tr>\n    <tr>\n      <th>SD</th>\n      <td>-0.076423</td>\n      <td>0.026519</td>\n      <td>-0.102943</td>\n    </tr>\n    <tr>\n      <th>TN</th>\n      <td>-0.047003</td>\n      <td>0.015407</td>\n      <td>-0.062411</td>\n    </tr>\n    <tr>\n      <th>TX</th>\n      <td>-0.161867</td>\n      <td>-0.040913</td>\n      <td>-0.120954</td>\n    </tr>\n    <tr>\n      <th>UT</th>\n      <td>-0.072992</td>\n      <td>0.046660</td>\n      <td>-0.119652</td>\n    </tr>\n    <tr>\n      <th>VA</th>\n      <td>-0.074930</td>\n      <td>0.023529</td>\n      <td>-0.098459</td>\n    </tr>\n    <tr>\n      <th>VT</th>\n      <td>-0.058992</td>\n      <td>0.027634</td>\n      <td>-0.086625</td>\n    </tr>\n    <tr>\n      <th>WI</th>\n      <td>-0.103530</td>\n      <td>0.025347</td>\n      <td>-0.128877</td>\n    </tr>\n    <tr>\n      <th>WY</th>\n      <td>-0.050587</td>\n      <td>0.029160</td>\n      <td>-0.079747</td>\n    </tr>\n    <tr>\n      <th>USA</th>\n      <td>-0.096136</td>\n      <td>0.037717</td>\n      <td>-0.133853</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by state for three known groups\n",
    "# Split into three dataframes\n",
    "df2_homeless = df2[df2['LIVARAG']=='Homeless'][['STFIPS']]\n",
    "df2_independent = df2[df2['LIVARAG']=='IndependentLiving'][['STFIPS']]\n",
    "df2_dependent = df2[df2['LIVARAG']=='DependLiving'][['STFIPS']]\n",
    "\n",
    "# Merge with Shapley values\n",
    "result_shapley = result[['LIVARAG']].rename(columns={'LIVARAG':'livarag_shapley'})\n",
    "result_state_homeless = pd.merge(result_shapley, df2_homeless, how='inner', left_index=True, right_index=True)\n",
    "result_state_independent = pd.merge(result_shapley, df2_independent, how='inner', left_index=True, right_index=True)\n",
    "result_state_dependent = pd.merge(result_shapley, df2_dependent, how='inner', left_index=True, right_index=True)\n",
    "result_state_housed = pd.concat([result_state_independent, result_state_dependent], axis=0)\n",
    "\n",
    "# Group to state-level averages and merge\n",
    "result_state_homeless_mean = result_state_homeless.groupby('STFIPS').mean().rename(columns={'livarag_shapley':'homeless_shapley'})\n",
    "result_state_housed_mean = result_state_housed.groupby('STFIPS').mean().rename(columns={'livarag_shapley':'housed_shapley'})\n",
    "result_state_mean = result_state_homeless_mean.copy()\n",
    "result_state_mean['housed_shapley'] = result_state_housed_mean['housed_shapley']\n",
    "\n",
    "# Add national averages\n",
    "homeless_avg = result_state_homeless['livarag_shapley'].mean()\n",
    "housed_avg = result_state_housed['livarag_shapley'].mean()\n",
    "national_avg = pd.DataFrame(data={'homeless_shapley':[homeless_avg], 'housed_shapley':housed_avg}, index=['USA'])\n",
    "result_state_mean = pd.concat([result_state_mean, national_avg], axis=0)\n",
    "\n",
    "# Calculate difference and ttest\n",
    "result_state_mean['difference_shapley'] = result_state_mean['homeless_shapley']-result_state_mean['housed_shapley']\n",
    "\n",
    "# Save, print results\n",
    "# result_state_mean.to_csv('shap_importance_by_state.csv')\n",
    "result_state_mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add t-test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "     Homeless    Housed  Difference       TStat    PValue Significance\nAK  -0.055358  0.049442   -0.104800  -18.704283  0.000000         ****\nAL  -0.066609  0.033245   -0.099854  -18.201098  0.000000         ****\nAR  -0.045466  0.032297   -0.077763  -11.423067  0.000000         ****\nCA  -0.158450  0.053071   -0.211521 -268.638088  0.000000         ****\nCO  -0.021190  0.037794   -0.058985  -23.730601  0.000000         ****\nCT  -0.080023  0.032898   -0.112921  -62.443598  0.000000         ****\nDC  -0.116890 -0.052680   -0.064209   -8.897108  0.000000         ****\nDE  -0.091809  0.056383   -0.148192  -37.738553  0.000000         ****\nGA  -0.111057  0.001415   -0.112471  -14.667945  0.000000         ****\nHI  -0.098834 -0.044641   -0.054193   -3.440540  0.000725         ****\nIA  -0.101672  0.016359   -0.118032  -24.489141  0.000000         ****\nID  -0.119816  0.011914   -0.131730   -2.749257  0.007697          ***\nIL  -0.145256 -0.069825   -0.075430  -22.132765  0.000000         ****\nIN  -0.125026  0.033729   -0.158756  -21.634786  0.000000         ****\nKS  -0.105221  0.020748   -0.125968   -8.786553  0.000000         ****\nKY  -0.114899  0.052957   -0.167855  -52.588493  0.000000         ****\nLA  -0.106424 -0.011155   -0.095268  -15.274474  0.000000         ****\nMA  -0.111383  0.049222   -0.160605 -240.596769  0.000000         ****\nMD  -0.164024  0.081754   -0.245778 -162.272825  0.000000         ****\nME  -0.020471  0.067789   -0.088260  -21.144592  0.000000         ****\nMI  -0.100128  0.032042   -0.132170  -49.273455  0.000000         ****\nMN  -0.018607 -0.007261   -0.011346   -4.006635  0.000062         ****\nMO  -0.104886  0.054892   -0.159778  -72.561699  0.000000         ****\nMS  -0.054201  0.034615   -0.088817  -16.075554  0.000000         ****\nMT  -0.019482  0.009486   -0.028968   -1.047481  0.298587             \nNC  -0.074169  0.059643   -0.133812  -58.978378  0.000000         ****\nND  -0.055402  0.013377   -0.068778   -2.233707  0.027980           **\nNE  -0.144916 -0.031235   -0.113682   -4.935876  0.000001         ****\nNH  -0.074476 -0.021811   -0.052665   -6.716264  0.000000         ****\nNJ  -0.114060  0.055770   -0.169830  -49.002215  0.000000         ****\nNM  -0.179784 -0.056526   -0.123259   -6.725213  0.000000         ****\nNV  -0.036247 -0.015763   -0.020484   -1.073952  0.283468             \nNY  -0.039729  0.028165   -0.067893 -105.550030  0.000000         ****\nOH   0.005004  0.009368   -0.004364   -1.152615  0.249112             \nOK   0.011532  0.028711   -0.017179   -3.883980  0.000107         ****\nPA  -0.025846 -0.055573    0.029727    5.286940  0.000000         ****\nPR  -0.132558  0.041833   -0.174391  -44.828043  0.000000         ****\nRI  -0.028326  0.080686   -0.109013  -30.944882  0.000000         ****\nSC  -0.049840  0.032186   -0.082026   -2.654057  0.010333           **\nSD  -0.076423  0.026519   -0.102943   -9.783280  0.000000         ****\nTN  -0.047003  0.015407   -0.062411  -33.566081  0.000000         ****\nTX  -0.161867 -0.040913   -0.120954  -26.570693  0.000000         ****\nUSA -0.096136  0.037717   -0.133853 -295.590062  0.000000         ****\nUT  -0.072992  0.046660   -0.119652  -42.662696  0.000000         ****\nVA  -0.074930  0.023529   -0.098459  -49.110511  0.000000         ****\nVT  -0.058992  0.027634   -0.086625  -23.881790  0.000000         ****\nWI  -0.103530  0.025347   -0.128877  -48.962373  0.000000         ****\nWY  -0.050587  0.029160   -0.079747   -7.784109  0.000000         ****",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Homeless</th>\n      <th>Housed</th>\n      <th>Difference</th>\n      <th>TStat</th>\n      <th>PValue</th>\n      <th>Significance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AK</th>\n      <td>-0.055358</td>\n      <td>0.049442</td>\n      <td>-0.104800</td>\n      <td>-18.704283</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>AL</th>\n      <td>-0.066609</td>\n      <td>0.033245</td>\n      <td>-0.099854</td>\n      <td>-18.201098</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>AR</th>\n      <td>-0.045466</td>\n      <td>0.032297</td>\n      <td>-0.077763</td>\n      <td>-11.423067</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>CA</th>\n      <td>-0.158450</td>\n      <td>0.053071</td>\n      <td>-0.211521</td>\n      <td>-268.638088</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>CO</th>\n      <td>-0.021190</td>\n      <td>0.037794</td>\n      <td>-0.058985</td>\n      <td>-23.730601</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>CT</th>\n      <td>-0.080023</td>\n      <td>0.032898</td>\n      <td>-0.112921</td>\n      <td>-62.443598</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>DC</th>\n      <td>-0.116890</td>\n      <td>-0.052680</td>\n      <td>-0.064209</td>\n      <td>-8.897108</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>DE</th>\n      <td>-0.091809</td>\n      <td>0.056383</td>\n      <td>-0.148192</td>\n      <td>-37.738553</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>GA</th>\n      <td>-0.111057</td>\n      <td>0.001415</td>\n      <td>-0.112471</td>\n      <td>-14.667945</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>HI</th>\n      <td>-0.098834</td>\n      <td>-0.044641</td>\n      <td>-0.054193</td>\n      <td>-3.440540</td>\n      <td>0.000725</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>IA</th>\n      <td>-0.101672</td>\n      <td>0.016359</td>\n      <td>-0.118032</td>\n      <td>-24.489141</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <td>-0.119816</td>\n      <td>0.011914</td>\n      <td>-0.131730</td>\n      <td>-2.749257</td>\n      <td>0.007697</td>\n      <td>***</td>\n    </tr>\n    <tr>\n      <th>IL</th>\n      <td>-0.145256</td>\n      <td>-0.069825</td>\n      <td>-0.075430</td>\n      <td>-22.132765</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>IN</th>\n      <td>-0.125026</td>\n      <td>0.033729</td>\n      <td>-0.158756</td>\n      <td>-21.634786</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>KS</th>\n      <td>-0.105221</td>\n      <td>0.020748</td>\n      <td>-0.125968</td>\n      <td>-8.786553</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>KY</th>\n      <td>-0.114899</td>\n      <td>0.052957</td>\n      <td>-0.167855</td>\n      <td>-52.588493</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>LA</th>\n      <td>-0.106424</td>\n      <td>-0.011155</td>\n      <td>-0.095268</td>\n      <td>-15.274474</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MA</th>\n      <td>-0.111383</td>\n      <td>0.049222</td>\n      <td>-0.160605</td>\n      <td>-240.596769</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MD</th>\n      <td>-0.164024</td>\n      <td>0.081754</td>\n      <td>-0.245778</td>\n      <td>-162.272825</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>ME</th>\n      <td>-0.020471</td>\n      <td>0.067789</td>\n      <td>-0.088260</td>\n      <td>-21.144592</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MI</th>\n      <td>-0.100128</td>\n      <td>0.032042</td>\n      <td>-0.132170</td>\n      <td>-49.273455</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MN</th>\n      <td>-0.018607</td>\n      <td>-0.007261</td>\n      <td>-0.011346</td>\n      <td>-4.006635</td>\n      <td>0.000062</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MO</th>\n      <td>-0.104886</td>\n      <td>0.054892</td>\n      <td>-0.159778</td>\n      <td>-72.561699</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MS</th>\n      <td>-0.054201</td>\n      <td>0.034615</td>\n      <td>-0.088817</td>\n      <td>-16.075554</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MT</th>\n      <td>-0.019482</td>\n      <td>0.009486</td>\n      <td>-0.028968</td>\n      <td>-1.047481</td>\n      <td>0.298587</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>NC</th>\n      <td>-0.074169</td>\n      <td>0.059643</td>\n      <td>-0.133812</td>\n      <td>-58.978378</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>ND</th>\n      <td>-0.055402</td>\n      <td>0.013377</td>\n      <td>-0.068778</td>\n      <td>-2.233707</td>\n      <td>0.027980</td>\n      <td>**</td>\n    </tr>\n    <tr>\n      <th>NE</th>\n      <td>-0.144916</td>\n      <td>-0.031235</td>\n      <td>-0.113682</td>\n      <td>-4.935876</td>\n      <td>0.000001</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>NH</th>\n      <td>-0.074476</td>\n      <td>-0.021811</td>\n      <td>-0.052665</td>\n      <td>-6.716264</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>NJ</th>\n      <td>-0.114060</td>\n      <td>0.055770</td>\n      <td>-0.169830</td>\n      <td>-49.002215</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>NM</th>\n      <td>-0.179784</td>\n      <td>-0.056526</td>\n      <td>-0.123259</td>\n      <td>-6.725213</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>NV</th>\n      <td>-0.036247</td>\n      <td>-0.015763</td>\n      <td>-0.020484</td>\n      <td>-1.073952</td>\n      <td>0.283468</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>NY</th>\n      <td>-0.039729</td>\n      <td>0.028165</td>\n      <td>-0.067893</td>\n      <td>-105.550030</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>OH</th>\n      <td>0.005004</td>\n      <td>0.009368</td>\n      <td>-0.004364</td>\n      <td>-1.152615</td>\n      <td>0.249112</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>OK</th>\n      <td>0.011532</td>\n      <td>0.028711</td>\n      <td>-0.017179</td>\n      <td>-3.883980</td>\n      <td>0.000107</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>PA</th>\n      <td>-0.025846</td>\n      <td>-0.055573</td>\n      <td>0.029727</td>\n      <td>5.286940</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>PR</th>\n      <td>-0.132558</td>\n      <td>0.041833</td>\n      <td>-0.174391</td>\n      <td>-44.828043</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>RI</th>\n      <td>-0.028326</td>\n      <td>0.080686</td>\n      <td>-0.109013</td>\n      <td>-30.944882</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>SC</th>\n      <td>-0.049840</td>\n      <td>0.032186</td>\n      <td>-0.082026</td>\n      <td>-2.654057</td>\n      <td>0.010333</td>\n      <td>**</td>\n    </tr>\n    <tr>\n      <th>SD</th>\n      <td>-0.076423</td>\n      <td>0.026519</td>\n      <td>-0.102943</td>\n      <td>-9.783280</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>TN</th>\n      <td>-0.047003</td>\n      <td>0.015407</td>\n      <td>-0.062411</td>\n      <td>-33.566081</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>TX</th>\n      <td>-0.161867</td>\n      <td>-0.040913</td>\n      <td>-0.120954</td>\n      <td>-26.570693</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>USA</th>\n      <td>-0.096136</td>\n      <td>0.037717</td>\n      <td>-0.133853</td>\n      <td>-295.590062</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>UT</th>\n      <td>-0.072992</td>\n      <td>0.046660</td>\n      <td>-0.119652</td>\n      <td>-42.662696</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>VA</th>\n      <td>-0.074930</td>\n      <td>0.023529</td>\n      <td>-0.098459</td>\n      <td>-49.110511</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>VT</th>\n      <td>-0.058992</td>\n      <td>0.027634</td>\n      <td>-0.086625</td>\n      <td>-23.881790</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>WI</th>\n      <td>-0.103530</td>\n      <td>0.025347</td>\n      <td>-0.128877</td>\n      <td>-48.962373</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>WY</th>\n      <td>-0.050587</td>\n      <td>0.029160</td>\n      <td>-0.079747</td>\n      <td>-7.784109</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Merge with Shapley values\n",
    "df2_1 = df2[df2['LIVARAG'] != 'Unknown']\n",
    "result_shapley = result[['LIVARAG']].rename(columns={'LIVARAG':'livarag_shapley'})\n",
    "result_state = pd.merge(result_shapley, df2_1[['STFIPS', 'LIVARAG']], how='inner', left_index=True, right_index=True)\n",
    "result_state['LIVARAG'] = result_state['LIVARAG'].replace(['IndependentLiving', 'DependLiving'], 'Housed')\n",
    "\n",
    "# Duplicate results listing them as national\n",
    "result_national = result_state.copy()\n",
    "result_national['STFIPS'] = 'USA'\n",
    "result_state_national = pd.concat([result_state, result_national])\n",
    "result_state_national = result_state_national.reset_index(drop=True)\n",
    "\n",
    "# Create assets for loop\n",
    "state_array = result_state_national['STFIPS'].sort_values().unique()\n",
    "state_list = state_array.tolist()\n",
    "state_list.append('USA')\n",
    "df_state = pd.DataFrame(columns=['Homeless', 'Housed', 'Difference', 'TStat', 'PValue', 'Significance'])\n",
    "\n",
    "# Loop through each state\n",
    "for s in state_list:\n",
    "    dftemp = result_state_national[result_state_national['STFIPS'] == s]\n",
    "\n",
    "    # Group by living arrangement and MOUD, then store those variables for later (if they exist)\n",
    "    dft_grouped = dftemp.groupby('LIVARAG')['livarag_shapley'].mean()\n",
    "\n",
    "    try:\n",
    "        homeless_moud = dft_grouped.loc['Homeless']\n",
    "    except KeyError:\n",
    "        print(f\"Insufficient homeless admissions to form a group in {s}\")\n",
    "        homeless_moud = np.nan\n",
    "\n",
    "    try:\n",
    "        housed_moud = dft_grouped.loc['Housed']\n",
    "    except KeyError:\n",
    "        print(f\"Insufficient housed admissions to form a group in {s}\")\n",
    "        housed_moud = np.nan\n",
    "\n",
    "    # Perform a t-test between the two groups\n",
    "    group_A_values = dftemp[dftemp['LIVARAG'] == 'Homeless']['livarag_shapley']\n",
    "    group_B_values = dftemp[dftemp['LIVARAG'] == 'Housed']['livarag_shapley']\n",
    "    t_stat, p_value = ttest_ind(group_A_values, group_B_values)\n",
    "\n",
    "    # Add significance based on p-value\n",
    "    if p_value < 0.001:\n",
    "        significance = '****'\n",
    "    elif p_value < 0.01:\n",
    "        significance = '***'\n",
    "    elif p_value < 0.05:\n",
    "        significance = '**'\n",
    "    elif p_value <0.1:\n",
    "        significance = '*'\n",
    "    else:\n",
    "        significance = ''\n",
    "\n",
    "    # Add values to a dictionary and round\n",
    "    dict_results = {'Homeless':homeless_moud, 'Housed':housed_moud, 'Difference':homeless_moud-housed_moud, 'TStat':t_stat, 'PValue':p_value}\n",
    "    for key, value in dict_results.items():\n",
    "        dict_results[key] = round(value, 6)\n",
    "\n",
    "    # Add significance and to dictionary and then dictionary to dataframe\n",
    "    dict_results['Significance'] = significance\n",
    "    df_state.loc[s] = dict_results\n",
    "\n",
    "# df_state.to_csv('shapley_with_ttest.csv') #uncomment to save file\n",
    "df_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "                 livarag_shapley\nSTFIPS LIVARAG                  \nAK     Homeless              265\n       Housed               1007\nAL     Homeless              258\n       Housed               4034\nAR     Homeless              143\n...                          ...\nVT     Housed               2440\nWI     Homeless              394\n       Housed               3695\nWY     Homeless               23\n       Housed                431\n\n[94 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>livarag_shapley</th>\n    </tr>\n    <tr>\n      <th>STFIPS</th>\n      <th>LIVARAG</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">AK</th>\n      <th>Homeless</th>\n      <td>265</td>\n    </tr>\n    <tr>\n      <th>Housed</th>\n      <td>1007</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">AL</th>\n      <th>Homeless</th>\n      <td>258</td>\n    </tr>\n    <tr>\n      <th>Housed</th>\n      <td>4034</td>\n    </tr>\n    <tr>\n      <th>AR</th>\n      <th>Homeless</th>\n      <td>143</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>VT</th>\n      <th>Housed</th>\n      <td>2440</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">WI</th>\n      <th>Homeless</th>\n      <td>394</td>\n    </tr>\n    <tr>\n      <th>Housed</th>\n      <td>3695</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">WY</th>\n      <th>Homeless</th>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>Housed</th>\n      <td>431</td>\n    </tr>\n  </tbody>\n</table>\n<p>94 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_state.groupby(['STFIPS', 'LIVARAG']).count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot Shapley values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show dependence plots for the top n features across all observations\n",
    "# NOTE: In order to get dependence plot to work, you must revert to matplotlib==3.1.3\n",
    "# Examples of dependence plots: https://slundberg.github.io/shap/notebooks/plots/dependence_plot.html\n",
    "\n",
    "shap.dependence_plot('LIVARAG', shap_values.values, X, x_jitter=0.3, alpha=0.005, interaction_index=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "           feature_name  feature_importance  feature_importance_out_of_100\n3              SERVICES            1.169295                       0.221355\n0                STFIPS            0.808112                       0.152981\n6               PSOURCE            0.297946                       0.056403\n5               NOPRIOR            0.260033                       0.049226\n31              HLTHINS            0.209499                       0.039660\n25                FREQ1            0.171629                       0.032491\n14              DSMCRIT            0.164464                       0.031134\n33  FREQ_ATND_SELF_HELP            0.139806                       0.026466\n18              PRIMINC            0.130791                       0.024760\n32              PRIMPAY            0.129681                       0.024550\n13              DAYWAIT            0.118846                       0.022498\n15                  AGE            0.105291                       0.019932\n8               PSYPROB            0.100620                       0.019048\n12              LIVARAG            0.099050                       0.018751\n54            DETEMPLOY            0.099006                       0.018742\n20                 SUB2            0.088223                       0.016701\n28             FRSTUSE1            0.079517                       0.015053\n21                 SUB3            0.075205                       0.014237\n7               ARRESTS            0.071864                       0.013604\n26                FREQ2            0.064924                       0.012290\n2               MARSTAT            0.063794                       0.012077\n4               DETCRIM            0.061273                       0.011599\n42             MTHAMFLG            0.060145                       0.011386\n27                FREQ3            0.059108                       0.011189\n1                  EDUC            0.051913                       0.009827\n37               HERFLG            0.051850                       0.009816\n16                 RACE            0.051645                       0.009777\n9                  PREG            0.051288                       0.009709\n29             FRSTUSE2            0.046171                       0.008740\n24               ROUTE3            0.043593                       0.008252\n22               ROUTE1            0.042054                       0.007961\n52                  IDU            0.038171                       0.007226\n23               ROUTE2            0.035611                       0.006741\n30             FRSTUSE3            0.035288                       0.006680\n36               MARFLG            0.033332                       0.006310\n19                 SUB1            0.028029                       0.005306\n34               ALCFLG            0.024488                       0.004636\n17               ETHNIC            0.022293                       0.004220\n39             OPSYNFLG            0.021677                       0.004104\n10               GENDER            0.021095                       0.003993\n35              COKEFLG            0.013388                       0.002534\n53              ALCDRUG            0.010694                       0.002024\n11                  VET            0.009283                       0.001757\n45              BENZFLG            0.008733                       0.001653\n51             OTHERFLG            0.003872                       0.000733\n38              METHFLG            0.003580                       0.000678\n44              STIMFLG            0.002831                       0.000536\n43              AMPHFLG            0.001696                       0.000321\n48             SEDHPFLG            0.001067                       0.000202\n40               PCPFLG            0.000306                       0.000058\n41              HALLFLG            0.000160                       0.000030\n50               OTCFLG            0.000090                       0.000017\n46              TRNQFLG            0.000058                       0.000011\n47              BARBFLG            0.000048                       0.000009\n49               INHFLG            0.000019                       0.000004",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_name</th>\n      <th>feature_importance</th>\n      <th>feature_importance_out_of_100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>SERVICES</td>\n      <td>1.169295</td>\n      <td>0.221355</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>STFIPS</td>\n      <td>0.808112</td>\n      <td>0.152981</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>PSOURCE</td>\n      <td>0.297946</td>\n      <td>0.056403</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NOPRIOR</td>\n      <td>0.260033</td>\n      <td>0.049226</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>HLTHINS</td>\n      <td>0.209499</td>\n      <td>0.039660</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>FREQ1</td>\n      <td>0.171629</td>\n      <td>0.032491</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DSMCRIT</td>\n      <td>0.164464</td>\n      <td>0.031134</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>FREQ_ATND_SELF_HELP</td>\n      <td>0.139806</td>\n      <td>0.026466</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>PRIMINC</td>\n      <td>0.130791</td>\n      <td>0.024760</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>PRIMPAY</td>\n      <td>0.129681</td>\n      <td>0.024550</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DAYWAIT</td>\n      <td>0.118846</td>\n      <td>0.022498</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>AGE</td>\n      <td>0.105291</td>\n      <td>0.019932</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>PSYPROB</td>\n      <td>0.100620</td>\n      <td>0.019048</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>LIVARAG</td>\n      <td>0.099050</td>\n      <td>0.018751</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>DETEMPLOY</td>\n      <td>0.099006</td>\n      <td>0.018742</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>SUB2</td>\n      <td>0.088223</td>\n      <td>0.016701</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>FRSTUSE1</td>\n      <td>0.079517</td>\n      <td>0.015053</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>SUB3</td>\n      <td>0.075205</td>\n      <td>0.014237</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ARRESTS</td>\n      <td>0.071864</td>\n      <td>0.013604</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>FREQ2</td>\n      <td>0.064924</td>\n      <td>0.012290</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MARSTAT</td>\n      <td>0.063794</td>\n      <td>0.012077</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DETCRIM</td>\n      <td>0.061273</td>\n      <td>0.011599</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>MTHAMFLG</td>\n      <td>0.060145</td>\n      <td>0.011386</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>FREQ3</td>\n      <td>0.059108</td>\n      <td>0.011189</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EDUC</td>\n      <td>0.051913</td>\n      <td>0.009827</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>HERFLG</td>\n      <td>0.051850</td>\n      <td>0.009816</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>RACE</td>\n      <td>0.051645</td>\n      <td>0.009777</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PREG</td>\n      <td>0.051288</td>\n      <td>0.009709</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>FRSTUSE2</td>\n      <td>0.046171</td>\n      <td>0.008740</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>ROUTE3</td>\n      <td>0.043593</td>\n      <td>0.008252</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>ROUTE1</td>\n      <td>0.042054</td>\n      <td>0.007961</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>IDU</td>\n      <td>0.038171</td>\n      <td>0.007226</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ROUTE2</td>\n      <td>0.035611</td>\n      <td>0.006741</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>FRSTUSE3</td>\n      <td>0.035288</td>\n      <td>0.006680</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>MARFLG</td>\n      <td>0.033332</td>\n      <td>0.006310</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>SUB1</td>\n      <td>0.028029</td>\n      <td>0.005306</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>ALCFLG</td>\n      <td>0.024488</td>\n      <td>0.004636</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ETHNIC</td>\n      <td>0.022293</td>\n      <td>0.004220</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>OPSYNFLG</td>\n      <td>0.021677</td>\n      <td>0.004104</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>GENDER</td>\n      <td>0.021095</td>\n      <td>0.003993</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>COKEFLG</td>\n      <td>0.013388</td>\n      <td>0.002534</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>ALCDRUG</td>\n      <td>0.010694</td>\n      <td>0.002024</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>VET</td>\n      <td>0.009283</td>\n      <td>0.001757</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>BENZFLG</td>\n      <td>0.008733</td>\n      <td>0.001653</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>OTHERFLG</td>\n      <td>0.003872</td>\n      <td>0.000733</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>METHFLG</td>\n      <td>0.003580</td>\n      <td>0.000678</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>STIMFLG</td>\n      <td>0.002831</td>\n      <td>0.000536</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>AMPHFLG</td>\n      <td>0.001696</td>\n      <td>0.000321</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>SEDHPFLG</td>\n      <td>0.001067</td>\n      <td>0.000202</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>PCPFLG</td>\n      <td>0.000306</td>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>HALLFLG</td>\n      <td>0.000160</td>\n      <td>0.000030</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>OTCFLG</td>\n      <td>0.000090</td>\n      <td>0.000017</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>TRNQFLG</td>\n      <td>0.000058</td>\n      <td>0.000011</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>BARBFLG</td>\n      <td>0.000048</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>INHFLG</td>\n      <td>0.000019</td>\n      <td>0.000004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "shap_importance\n",
    "# shap_importance.to_csv('shap_importance.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grouped feature importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "           feature_name             feature_label       feature_category  \\\n0              SERVICES         treatment service   coordination of care   \n1                STFIPS                state code             geographic   \n2               PSOURCE           referral source   coordination of care   \n3               NOPRIOR          prior treatments        medical history   \n4               HLTHINS          health insurance               economic   \n5                 FREQ1         primary frequency  substance use history   \n6               DSMCRIT             dsm diagnosis        medical history   \n7   FREQ_ATND_SELF_HELP           self help group        medical history   \n8               PRIMINC             income source               economic   \n9               PRIMPAY            payment source               economic   \n10              DAYWAIT              days waiting   coordination of care   \n11                  AGE                       age            demographic   \n12              PSYPROB           mental disorder        medical history   \n13              LIVARAG        living arrangement               economic   \n14            DETEMPLOY                employment               economic   \n15                 SUB2       secondary substance  substance use history   \n16             FRSTUSE1         primary first use  substance use history   \n17                 SUB3        tertiary substance  substance use history   \n18              ARRESTS                   arrests       personal history   \n19                FREQ2       secondary frequency  substance use history   \n20              MARSTAT            marital status       personal history   \n21              DETCRIM  ciminal justice referral   coordination of care   \n22             MTHAMFLG           methamphetamine  substance use history   \n23                FREQ3        tertiary frequency  substance use history   \n24                 EDUC                 education       personal history   \n25               HERFLG                    heroin  substance use history   \n26                 RACE                      race            demographic   \n27                 PREG                  pregnant        medical history   \n28             FRSTUSE2       secondary first use  substance use history   \n29               ROUTE3            tertiary route  substance use history   \n30               ROUTE1             primary route  substance use history   \n31                  IDU                   iv drug  substance use history   \n32               ROUTE2           secondary route  substance use history   \n33             FRSTUSE3        tertiary first use  substance use history   \n34               MARFLG                 marijuana  substance use history   \n35                 SUB1         primary substance  substance use history   \n36               ALCFLG                   alcohol  substance use history   \n37               ETHNIC                 ethnicity            demographic   \n38             OPSYNFLG                   opiates  substance use history   \n39               GENDER                    gender            demographic   \n40              COKEFLG                   cocaine  substance use history   \n41              ALCDRUG        substance use type  substance use history   \n42                  VET            veteran status       personal history   \n43              BENZFLG           benzodiazepines  substance use history   \n44             OTHERFLG                other drug  substance use history   \n45              METHFLG                 methadone  substance use history   \n46              STIMFLG                stimulants  substance use history   \n47              AMPHFLG              amphetamines  substance use history   \n48             SEDHPFLG                 sedatives  substance use history   \n49               PCPFLG                       pcp  substance use history   \n50              HALLFLG             hallucinogens  substance use history   \n51               OTCFLG                  otc meds  substance use history   \n52              TRNQFLG             tranquilizers  substance use history   \n53              BARBFLG              barbiturates  substance use history   \n54               INHFLG                 inhalants  substance use history   \n\n    feature_importance  feature_importance_out_of_100  \n0             1.169295                       0.221355  \n1             0.808112                       0.152981  \n2             0.297946                       0.056403  \n3             0.260033                       0.049226  \n4             0.209499                       0.039660  \n5             0.171629                       0.032491  \n6             0.164464                       0.031134  \n7             0.139806                       0.026466  \n8             0.130791                       0.024760  \n9             0.129681                       0.024550  \n10            0.118846                       0.022498  \n11            0.105291                       0.019932  \n12            0.100620                       0.019048  \n13            0.099050                       0.018751  \n14            0.099006                       0.018742  \n15            0.088223                       0.016701  \n16            0.079517                       0.015053  \n17            0.075205                       0.014237  \n18            0.071864                       0.013604  \n19            0.064924                       0.012290  \n20            0.063794                       0.012077  \n21            0.061273                       0.011599  \n22            0.060145                       0.011386  \n23            0.059108                       0.011189  \n24            0.051913                       0.009827  \n25            0.051850                       0.009816  \n26            0.051645                       0.009777  \n27            0.051288                       0.009709  \n28            0.046171                       0.008740  \n29            0.043593                       0.008252  \n30            0.042054                       0.007961  \n31            0.038171                       0.007226  \n32            0.035611                       0.006741  \n33            0.035288                       0.006680  \n34            0.033332                       0.006310  \n35            0.028029                       0.005306  \n36            0.024488                       0.004636  \n37            0.022293                       0.004220  \n38            0.021677                       0.004104  \n39            0.021095                       0.003993  \n40            0.013388                       0.002534  \n41            0.010694                       0.002024  \n42            0.009283                       0.001757  \n43            0.008733                       0.001653  \n44            0.003872                       0.000733  \n45            0.003580                       0.000678  \n46            0.002831                       0.000536  \n47            0.001696                       0.000321  \n48            0.001067                       0.000202  \n49            0.000306                       0.000058  \n50            0.000160                       0.000030  \n51            0.000090                       0.000017  \n52            0.000058                       0.000011  \n53            0.000048                       0.000009  \n54            0.000019                       0.000004  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_name</th>\n      <th>feature_label</th>\n      <th>feature_category</th>\n      <th>feature_importance</th>\n      <th>feature_importance_out_of_100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SERVICES</td>\n      <td>treatment service</td>\n      <td>coordination of care</td>\n      <td>1.169295</td>\n      <td>0.221355</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>STFIPS</td>\n      <td>state code</td>\n      <td>geographic</td>\n      <td>0.808112</td>\n      <td>0.152981</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PSOURCE</td>\n      <td>referral source</td>\n      <td>coordination of care</td>\n      <td>0.297946</td>\n      <td>0.056403</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NOPRIOR</td>\n      <td>prior treatments</td>\n      <td>medical history</td>\n      <td>0.260033</td>\n      <td>0.049226</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HLTHINS</td>\n      <td>health insurance</td>\n      <td>economic</td>\n      <td>0.209499</td>\n      <td>0.039660</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>FREQ1</td>\n      <td>primary frequency</td>\n      <td>substance use history</td>\n      <td>0.171629</td>\n      <td>0.032491</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DSMCRIT</td>\n      <td>dsm diagnosis</td>\n      <td>medical history</td>\n      <td>0.164464</td>\n      <td>0.031134</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>FREQ_ATND_SELF_HELP</td>\n      <td>self help group</td>\n      <td>medical history</td>\n      <td>0.139806</td>\n      <td>0.026466</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>PRIMINC</td>\n      <td>income source</td>\n      <td>economic</td>\n      <td>0.130791</td>\n      <td>0.024760</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PRIMPAY</td>\n      <td>payment source</td>\n      <td>economic</td>\n      <td>0.129681</td>\n      <td>0.024550</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DAYWAIT</td>\n      <td>days waiting</td>\n      <td>coordination of care</td>\n      <td>0.118846</td>\n      <td>0.022498</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>AGE</td>\n      <td>age</td>\n      <td>demographic</td>\n      <td>0.105291</td>\n      <td>0.019932</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>PSYPROB</td>\n      <td>mental disorder</td>\n      <td>medical history</td>\n      <td>0.100620</td>\n      <td>0.019048</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>LIVARAG</td>\n      <td>living arrangement</td>\n      <td>economic</td>\n      <td>0.099050</td>\n      <td>0.018751</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DETEMPLOY</td>\n      <td>employment</td>\n      <td>economic</td>\n      <td>0.099006</td>\n      <td>0.018742</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SUB2</td>\n      <td>secondary substance</td>\n      <td>substance use history</td>\n      <td>0.088223</td>\n      <td>0.016701</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>FRSTUSE1</td>\n      <td>primary first use</td>\n      <td>substance use history</td>\n      <td>0.079517</td>\n      <td>0.015053</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SUB3</td>\n      <td>tertiary substance</td>\n      <td>substance use history</td>\n      <td>0.075205</td>\n      <td>0.014237</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ARRESTS</td>\n      <td>arrests</td>\n      <td>personal history</td>\n      <td>0.071864</td>\n      <td>0.013604</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>FREQ2</td>\n      <td>secondary frequency</td>\n      <td>substance use history</td>\n      <td>0.064924</td>\n      <td>0.012290</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>MARSTAT</td>\n      <td>marital status</td>\n      <td>personal history</td>\n      <td>0.063794</td>\n      <td>0.012077</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>DETCRIM</td>\n      <td>ciminal justice referral</td>\n      <td>coordination of care</td>\n      <td>0.061273</td>\n      <td>0.011599</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>MTHAMFLG</td>\n      <td>methamphetamine</td>\n      <td>substance use history</td>\n      <td>0.060145</td>\n      <td>0.011386</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>FREQ3</td>\n      <td>tertiary frequency</td>\n      <td>substance use history</td>\n      <td>0.059108</td>\n      <td>0.011189</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>EDUC</td>\n      <td>education</td>\n      <td>personal history</td>\n      <td>0.051913</td>\n      <td>0.009827</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>HERFLG</td>\n      <td>heroin</td>\n      <td>substance use history</td>\n      <td>0.051850</td>\n      <td>0.009816</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>RACE</td>\n      <td>race</td>\n      <td>demographic</td>\n      <td>0.051645</td>\n      <td>0.009777</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>PREG</td>\n      <td>pregnant</td>\n      <td>medical history</td>\n      <td>0.051288</td>\n      <td>0.009709</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>FRSTUSE2</td>\n      <td>secondary first use</td>\n      <td>substance use history</td>\n      <td>0.046171</td>\n      <td>0.008740</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>ROUTE3</td>\n      <td>tertiary route</td>\n      <td>substance use history</td>\n      <td>0.043593</td>\n      <td>0.008252</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>ROUTE1</td>\n      <td>primary route</td>\n      <td>substance use history</td>\n      <td>0.042054</td>\n      <td>0.007961</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>IDU</td>\n      <td>iv drug</td>\n      <td>substance use history</td>\n      <td>0.038171</td>\n      <td>0.007226</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>ROUTE2</td>\n      <td>secondary route</td>\n      <td>substance use history</td>\n      <td>0.035611</td>\n      <td>0.006741</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>FRSTUSE3</td>\n      <td>tertiary first use</td>\n      <td>substance use history</td>\n      <td>0.035288</td>\n      <td>0.006680</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>MARFLG</td>\n      <td>marijuana</td>\n      <td>substance use history</td>\n      <td>0.033332</td>\n      <td>0.006310</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>SUB1</td>\n      <td>primary substance</td>\n      <td>substance use history</td>\n      <td>0.028029</td>\n      <td>0.005306</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>ALCFLG</td>\n      <td>alcohol</td>\n      <td>substance use history</td>\n      <td>0.024488</td>\n      <td>0.004636</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>ETHNIC</td>\n      <td>ethnicity</td>\n      <td>demographic</td>\n      <td>0.022293</td>\n      <td>0.004220</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>OPSYNFLG</td>\n      <td>opiates</td>\n      <td>substance use history</td>\n      <td>0.021677</td>\n      <td>0.004104</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>GENDER</td>\n      <td>gender</td>\n      <td>demographic</td>\n      <td>0.021095</td>\n      <td>0.003993</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>COKEFLG</td>\n      <td>cocaine</td>\n      <td>substance use history</td>\n      <td>0.013388</td>\n      <td>0.002534</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>ALCDRUG</td>\n      <td>substance use type</td>\n      <td>substance use history</td>\n      <td>0.010694</td>\n      <td>0.002024</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>VET</td>\n      <td>veteran status</td>\n      <td>personal history</td>\n      <td>0.009283</td>\n      <td>0.001757</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>BENZFLG</td>\n      <td>benzodiazepines</td>\n      <td>substance use history</td>\n      <td>0.008733</td>\n      <td>0.001653</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>OTHERFLG</td>\n      <td>other drug</td>\n      <td>substance use history</td>\n      <td>0.003872</td>\n      <td>0.000733</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>METHFLG</td>\n      <td>methadone</td>\n      <td>substance use history</td>\n      <td>0.003580</td>\n      <td>0.000678</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>STIMFLG</td>\n      <td>stimulants</td>\n      <td>substance use history</td>\n      <td>0.002831</td>\n      <td>0.000536</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>AMPHFLG</td>\n      <td>amphetamines</td>\n      <td>substance use history</td>\n      <td>0.001696</td>\n      <td>0.000321</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>SEDHPFLG</td>\n      <td>sedatives</td>\n      <td>substance use history</td>\n      <td>0.001067</td>\n      <td>0.000202</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>PCPFLG</td>\n      <td>pcp</td>\n      <td>substance use history</td>\n      <td>0.000306</td>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>HALLFLG</td>\n      <td>hallucinogens</td>\n      <td>substance use history</td>\n      <td>0.000160</td>\n      <td>0.000030</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>OTCFLG</td>\n      <td>otc meds</td>\n      <td>substance use history</td>\n      <td>0.000090</td>\n      <td>0.000017</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>TRNQFLG</td>\n      <td>tranquilizers</td>\n      <td>substance use history</td>\n      <td>0.000058</td>\n      <td>0.000011</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>BARBFLG</td>\n      <td>barbiturates</td>\n      <td>substance use history</td>\n      <td>0.000048</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>INHFLG</td>\n      <td>inhalants</td>\n      <td>substance use history</td>\n      <td>0.000019</td>\n      <td>0.000004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "g = pd.read_csv('shap_importance_encoded.csv')  #update label and category, then regroup\n",
    "g"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "feature_category\ncoordination of care     0.311856\nsubstance use history    0.197930\ngeographic               0.152981\nmedical history          0.135583\neconomic                 0.126462\ndemographic              0.037923\npersonal history         0.037266\nName: feature_importance_out_of_100, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_grouped = g.groupby('feature_category').sum()['feature_importance_out_of_100'].sort_values(ascending=False)\n",
    "# g_grouped.to_csv('shap_importance_grouped.csv')\n",
    "g_grouped"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "               feature_label  feature_importance_out_of_100\n0          treatment service                       0.221355\n1                 state code                       0.152981\n2            referral source                       0.056403\n3           prior treatments                       0.049226\n4           health insurance                       0.039660\n5          primary frequency                       0.032491\n6              dsm diagnosis                       0.031134\n7            self help group                       0.026466\n8              income source                       0.024760\n9             payment source                       0.024550\n10              days waiting                       0.022498\n11                       age                       0.019932\n12           mental disorder                       0.019048\n13        living arrangement                       0.018751\n14                employment                       0.018742\n15       secondary substance                       0.016701\n16         primary first use                       0.015053\n17        tertiary substance                       0.014237\n18                   arrests                       0.013604\n19       secondary frequency                       0.012290\n20            marital status                       0.012077\n21  ciminal justice referral                       0.011599\n22           methamphetamine                       0.011386\n23        tertiary frequency                       0.011189\n24                 education                       0.009827\n25                    heroin                       0.009816\n26                      race                       0.009777\n27                  pregnant                       0.009709\n28       secondary first use                       0.008740\n29            tertiary route                       0.008252\n30             primary route                       0.007961\n31                   iv drug                       0.007226\n32           secondary route                       0.006741\n33        tertiary first use                       0.006680\n34                 marijuana                       0.006310\n35         primary substance                       0.005306\n36                   alcohol                       0.004636\n37                 ethnicity                       0.004220\n38                   opiates                       0.004104\n39                    gender                       0.003993\n40                   cocaine                       0.002534\n41        substance use type                       0.002024\n42            veteran status                       0.001757\n43           benzodiazepines                       0.001653\n44                other drug                       0.000733\n45                 methadone                       0.000678\n46                stimulants                       0.000536\n47              amphetamines                       0.000321\n48                 sedatives                       0.000202\n49                       pcp                       0.000058\n50             hallucinogens                       0.000030\n51                  otc meds                       0.000017\n52             tranquilizers                       0.000011\n53              barbiturates                       0.000009\n54                 inhalants                       0.000004",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_label</th>\n      <th>feature_importance_out_of_100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>treatment service</td>\n      <td>0.221355</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>state code</td>\n      <td>0.152981</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>referral source</td>\n      <td>0.056403</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>prior treatments</td>\n      <td>0.049226</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>health insurance</td>\n      <td>0.039660</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>primary frequency</td>\n      <td>0.032491</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dsm diagnosis</td>\n      <td>0.031134</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>self help group</td>\n      <td>0.026466</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>income source</td>\n      <td>0.024760</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>payment source</td>\n      <td>0.024550</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>days waiting</td>\n      <td>0.022498</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>age</td>\n      <td>0.019932</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mental disorder</td>\n      <td>0.019048</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>living arrangement</td>\n      <td>0.018751</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>employment</td>\n      <td>0.018742</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>secondary substance</td>\n      <td>0.016701</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>primary first use</td>\n      <td>0.015053</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>tertiary substance</td>\n      <td>0.014237</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>arrests</td>\n      <td>0.013604</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>secondary frequency</td>\n      <td>0.012290</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>marital status</td>\n      <td>0.012077</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ciminal justice referral</td>\n      <td>0.011599</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>methamphetamine</td>\n      <td>0.011386</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>tertiary frequency</td>\n      <td>0.011189</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>education</td>\n      <td>0.009827</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>heroin</td>\n      <td>0.009816</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>race</td>\n      <td>0.009777</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>pregnant</td>\n      <td>0.009709</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>secondary first use</td>\n      <td>0.008740</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>tertiary route</td>\n      <td>0.008252</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>primary route</td>\n      <td>0.007961</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>iv drug</td>\n      <td>0.007226</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>secondary route</td>\n      <td>0.006741</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>tertiary first use</td>\n      <td>0.006680</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>marijuana</td>\n      <td>0.006310</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>primary substance</td>\n      <td>0.005306</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>alcohol</td>\n      <td>0.004636</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>ethnicity</td>\n      <td>0.004220</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>opiates</td>\n      <td>0.004104</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>gender</td>\n      <td>0.003993</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>cocaine</td>\n      <td>0.002534</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>substance use type</td>\n      <td>0.002024</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>veteran status</td>\n      <td>0.001757</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>benzodiazepines</td>\n      <td>0.001653</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>other drug</td>\n      <td>0.000733</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>methadone</td>\n      <td>0.000678</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>stimulants</td>\n      <td>0.000536</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>amphetamines</td>\n      <td>0.000321</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>sedatives</td>\n      <td>0.000202</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>pcp</td>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>hallucinogens</td>\n      <td>0.000030</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>otc meds</td>\n      <td>0.000017</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>tranquilizers</td>\n      <td>0.000011</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>barbiturates</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>inhalants</td>\n      <td>0.000004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.sort_values(by='feature_importance_out_of_100', ascending=False)[['feature_label', 'feature_importance_out_of_100']].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
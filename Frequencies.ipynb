{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Load in data\n",
    "admissions = 'tedsa_puf_2019.csv'\n",
    "df_raw = pd.read_csv(f'../../Downloads/{admissions}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter out select rows and columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 5 columns (57 remain)\n",
      "Dropped 1,340,233 observations or 71.9% of the data (524,134 rows remain)\n"
     ]
    }
   ],
   "source": [
    "# Get count of original number of rows\n",
    "old_rows = len(df_raw)\n",
    "\n",
    "# Drop defined columns (year of admission, case id, geographic metro area, geographic division, geographic region)\n",
    "columns_to_drop = ['ADMYR', 'CASEID', 'CBSA2010', 'DIVISION', 'REGION']\n",
    "df = df_raw.drop(columns=columns_to_drop)\n",
    "print(f'Dropped {len(columns_to_drop)} columns ({len(df.columns)} remain)')\n",
    "\n",
    "# Drop values where dependent variable is unknown\n",
    "df = df[df['METHUSE'] != -9]\n",
    "\n",
    "# Only keep patients admitted with self-described use of an opioid as their primary substance use (i.e., SUB1 = 5, 6, or 7)\n",
    "df = df[df['SUB1'].between(5, 7)]\n",
    "new_rows = len(df)\n",
    "percent_change = round(100*(old_rows-new_rows)/old_rows, 1)\n",
    "print(f'Dropped {\"{:,}\".format(old_rows-new_rows)} observations or {percent_change}% of the data ({\"{:,}\".format(new_rows)} rows remain)')\n",
    "\n",
    "df = df.reset_index(drop='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make dataset human-readable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load in variable dictionary\n",
    "with open('VariableDictionary.txt') as file:\n",
    "    variable_dict_string = file.read()\n",
    "    variable_dict = ast.literal_eval(variable_dict_string)\n",
    "\n",
    "# Rename entries in column according to dictionary\n",
    "df2 = df.copy()\n",
    "for col, col_dict in variable_dict.items():\n",
    "    if col in df2.columns:\n",
    "        for old_value, new_value in variable_dict[col].items():\n",
    "            df2[col] = df2[col].replace(old_value, new_value)\n",
    "\n",
    "# Rename \"-9\" values as \"Unknown\"\n",
    "for col in df2.columns:\n",
    "    df2[col] = df2[col].replace(-9, 'Unknown')\n",
    "\n",
    "# Merge DETNLF (detailed not in labor force) into EMPLOY==4 (not in labor force)\n",
    "detailed_employ = []\n",
    "\n",
    "for idx, value in df2.iterrows():\n",
    "    if value['EMPLOY'] == 'NotInLaborForce':\n",
    "        if value['DETNLF'] == 'Unknown':\n",
    "            # Assign 'UnknownNotInLaborForce' if 'NotInLaborForce' and 'Unknown'\n",
    "            detailed_employ.append('UnknownNotInLaborForce')\n",
    "        else:\n",
    "            # Otherwise, assign as the DETNLF value\n",
    "            detailed_employ.append(value['DETNLF'])\n",
    "    else:\n",
    "        # Assign the EMPLOY value if not 'NotInLaborForce'\n",
    "        detailed_employ.append(value['EMPLOY'])\n",
    "\n",
    "# Add a new column for detailed employment and drop the two source columns\n",
    "df2['DETEMPLOY'] = detailed_employ\n",
    "df2 = df2.drop(columns=['EMPLOY', 'DETNLF'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Percent receiving MOUD by variable subgroup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "         group                subgroup  total_admissions  \\\n0       STFIPS                      AK              1603   \n1       STFIPS                      AL              5774   \n2       STFIPS                      AR              1947   \n3       STFIPS                      AZ             10189   \n4       STFIPS                      CA             42031   \n..         ...                     ...               ...   \n334  DETEMPLOY       RetiredOrDisabled             38813   \n335  DETEMPLOY                 Student              1784   \n336  DETEMPLOY              Unemployed            191417   \n337  DETEMPLOY                 Unknown             23056   \n338  DETEMPLOY  UnknownNotInLaborForce             22478   \n\n     group_share_of_admissions  percent_receiving_moud  \n0                     0.003058                0.492826  \n1                     0.011016                0.297194  \n2                     0.003715                0.337956  \n3                     0.019440                0.181176  \n4                     0.080191                0.587804  \n..                         ...                     ...  \n334                   0.074052                0.489759  \n335                   0.003404                0.314462  \n336                   0.365206                0.372052  \n337                   0.043989                0.573603  \n338                   0.042886                0.557745  \n\n[339 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>subgroup</th>\n      <th>total_admissions</th>\n      <th>group_share_of_admissions</th>\n      <th>percent_receiving_moud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>STFIPS</td>\n      <td>AK</td>\n      <td>1603</td>\n      <td>0.003058</td>\n      <td>0.492826</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>STFIPS</td>\n      <td>AL</td>\n      <td>5774</td>\n      <td>0.011016</td>\n      <td>0.297194</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>STFIPS</td>\n      <td>AR</td>\n      <td>1947</td>\n      <td>0.003715</td>\n      <td>0.337956</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>STFIPS</td>\n      <td>AZ</td>\n      <td>10189</td>\n      <td>0.019440</td>\n      <td>0.181176</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>STFIPS</td>\n      <td>CA</td>\n      <td>42031</td>\n      <td>0.080191</td>\n      <td>0.587804</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>DETEMPLOY</td>\n      <td>RetiredOrDisabled</td>\n      <td>38813</td>\n      <td>0.074052</td>\n      <td>0.489759</td>\n    </tr>\n    <tr>\n      <th>335</th>\n      <td>DETEMPLOY</td>\n      <td>Student</td>\n      <td>1784</td>\n      <td>0.003404</td>\n      <td>0.314462</td>\n    </tr>\n    <tr>\n      <th>336</th>\n      <td>DETEMPLOY</td>\n      <td>Unemployed</td>\n      <td>191417</td>\n      <td>0.365206</td>\n      <td>0.372052</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>DETEMPLOY</td>\n      <td>Unknown</td>\n      <td>23056</td>\n      <td>0.043989</td>\n      <td>0.573603</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>DETEMPLOY</td>\n      <td>UnknownNotInLaborForce</td>\n      <td>22478</td>\n      <td>0.042886</td>\n      <td>0.557745</td>\n    </tr>\n  </tbody>\n</table>\n<p>339 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(df2)\n",
    "df3 = df2.copy()\n",
    "df3 = df3.replace({'MethUse':1, 'NoMethUse':0})\n",
    "\n",
    "df_freq = pd.DataFrame()\n",
    "\n",
    "for col in df3.columns:\n",
    "\n",
    "    dff = df3.groupby([col])['METHUSE'].mean()\n",
    "    dff = pd.DataFrame(dff)\n",
    "\n",
    "    dff2 = df3.groupby([col])['METHUSE'].count()\n",
    "    dff2 = pd.DataFrame(dff2)\n",
    "\n",
    "    dff3 = pd.merge(dff, dff2, how='inner', left_index=True, right_index=True)\n",
    "    dff3 = dff3.reset_index()\n",
    "    dff3 = dff3.rename(columns={'METHUSE_x': 'percent_receiving_moud', 'METHUSE_y': 'total_admissions', col: 'subgroup'})\n",
    "    dff3['group_share_of_admissions'] = dff3['total_admissions']/total\n",
    "    dff3 = dff3[['subgroup', 'total_admissions', 'group_share_of_admissions', 'percent_receiving_moud']]\n",
    "    dff3.insert(0, 'group', col)\n",
    "\n",
    "    df_freq = pd.concat([df_freq, dff3])\n",
    "\n",
    "df_freq = df_freq.reset_index(drop=True)\n",
    "df_freq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "df_freq.to_csv('percent_receiving_moud.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Describe MOUD treatment frequency by state and living status\n",
    "Calculate the percent difference between the homeless and housed as well as its statistical difference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    Homeless  Housed  PercentDifference      TStat    PValue Significance\nAK       333    1214          -0.725700  -4.249484  0.000023         ****\nAL       379    5170          -0.926692  -8.004596  0.000000         ****\nAR       203    1741          -0.883400  -7.541382  0.000000         ****\nCA     10568   31443          -0.663900 -61.263606  0.000000         ****\nCO      1861   11203          -0.833884  -0.181478  0.855995             \nCT      2867   19592          -0.853665 -17.040277  0.000000         ****\nDC       703     835          -0.158084   1.725765  0.084591            *\nDE       887    7907          -0.887821  -9.880705  0.000000         ****\nGA       327    2514          -0.869928  -1.155031  0.248175             \nHI        66     179          -0.631285  -0.327188  0.743808             \nIA       615    1558          -0.605263  -4.681897  0.000003         ****\nID        12      85          -0.858824  -0.532160  0.595857             \nIL      2126   14129          -0.849529  -5.841952  0.000000         ****\nIN       525    6627          -0.920779  -6.199392  0.000000         ****\nKS        40     249          -0.839357  -1.235859  0.217522             \nKY      1505    4926          -0.694478 -18.254217  0.000000         ****\nLA       307    1749          -0.824471  -0.768877  0.442054             \nMA     12997   30690          -0.576507 -18.944718  0.000000         ****\nMD      9185   53807          -0.829297 -66.669003  0.000000         ****\nME       543    3184          -0.829460  -0.600491  0.548215             \nMI      6014   23110          -0.739766  -8.003398  0.000000         ****\nMN      1664    8282          -0.799082   2.556019  0.010602           **\nMO      1241    7184          -0.827255  -3.137250  0.001711          ***\nMS        88    1148          -0.923345  -0.697494  0.485625             \nMT        22      84          -0.738095        NaN       NaN             \nNC       756   14531          -0.947973  -5.059808  0.000000         ****\nND        16     115          -0.860870   0.221732  0.824873             \nNE        49     306          -0.839869  -3.127550  0.001909          ***\nNH       462     695          -0.335252   0.560195  0.575455             \nNJ      2249   28658          -0.921523   0.295288  0.767776             \nNM        91     743          -0.877524   2.185773  0.029110           **\nNV        42     497          -0.915493   1.727083  0.084728            *\nNY     18260   72025          -0.746477 -36.693141  0.000000         ****\nOH       817    7278          -0.887744   4.203492  0.000027         ****\nOK       214    2360          -0.909322        NaN       NaN             \nPA       906    9045          -0.899834  -1.810339  0.070273            *\nPR       139    1008          -0.862103  -2.964223  0.003097          ***\nRI       597    5083          -0.882550 -12.808389  0.000000         ****\nSC         5      67          -0.925373   0.457800  0.648514             \nSD        21     477          -0.955975  -2.873357  0.004236          ***\nTN      1223    5828          -0.790151   0.415806  0.677564             \nTX      1789    5816          -0.692400 -17.924876  0.000000         ****\nUT      1526    3032          -0.496702 -10.823623  0.000000         ****\nVA       541    5823          -0.907093        NaN       NaN             \nVT       429    2687          -0.840342  -2.208600  0.027275           **\nWI       587    5081          -0.884472  -6.132794  0.000000         ****\nWY        27     618          -0.956311   1.765108  0.078020            *\nUSA    85824  410383          -0.790869 -77.837711  0.000000         ****",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Homeless</th>\n      <th>Housed</th>\n      <th>PercentDifference</th>\n      <th>TStat</th>\n      <th>PValue</th>\n      <th>Significance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AK</th>\n      <td>333</td>\n      <td>1214</td>\n      <td>-0.725700</td>\n      <td>-4.249484</td>\n      <td>0.000023</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>AL</th>\n      <td>379</td>\n      <td>5170</td>\n      <td>-0.926692</td>\n      <td>-8.004596</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>AR</th>\n      <td>203</td>\n      <td>1741</td>\n      <td>-0.883400</td>\n      <td>-7.541382</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>CA</th>\n      <td>10568</td>\n      <td>31443</td>\n      <td>-0.663900</td>\n      <td>-61.263606</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>CO</th>\n      <td>1861</td>\n      <td>11203</td>\n      <td>-0.833884</td>\n      <td>-0.181478</td>\n      <td>0.855995</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>CT</th>\n      <td>2867</td>\n      <td>19592</td>\n      <td>-0.853665</td>\n      <td>-17.040277</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>DC</th>\n      <td>703</td>\n      <td>835</td>\n      <td>-0.158084</td>\n      <td>1.725765</td>\n      <td>0.084591</td>\n      <td>*</td>\n    </tr>\n    <tr>\n      <th>DE</th>\n      <td>887</td>\n      <td>7907</td>\n      <td>-0.887821</td>\n      <td>-9.880705</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>GA</th>\n      <td>327</td>\n      <td>2514</td>\n      <td>-0.869928</td>\n      <td>-1.155031</td>\n      <td>0.248175</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>HI</th>\n      <td>66</td>\n      <td>179</td>\n      <td>-0.631285</td>\n      <td>-0.327188</td>\n      <td>0.743808</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>IA</th>\n      <td>615</td>\n      <td>1558</td>\n      <td>-0.605263</td>\n      <td>-4.681897</td>\n      <td>0.000003</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <td>12</td>\n      <td>85</td>\n      <td>-0.858824</td>\n      <td>-0.532160</td>\n      <td>0.595857</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>IL</th>\n      <td>2126</td>\n      <td>14129</td>\n      <td>-0.849529</td>\n      <td>-5.841952</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>IN</th>\n      <td>525</td>\n      <td>6627</td>\n      <td>-0.920779</td>\n      <td>-6.199392</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>KS</th>\n      <td>40</td>\n      <td>249</td>\n      <td>-0.839357</td>\n      <td>-1.235859</td>\n      <td>0.217522</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>KY</th>\n      <td>1505</td>\n      <td>4926</td>\n      <td>-0.694478</td>\n      <td>-18.254217</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>LA</th>\n      <td>307</td>\n      <td>1749</td>\n      <td>-0.824471</td>\n      <td>-0.768877</td>\n      <td>0.442054</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>MA</th>\n      <td>12997</td>\n      <td>30690</td>\n      <td>-0.576507</td>\n      <td>-18.944718</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MD</th>\n      <td>9185</td>\n      <td>53807</td>\n      <td>-0.829297</td>\n      <td>-66.669003</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>ME</th>\n      <td>543</td>\n      <td>3184</td>\n      <td>-0.829460</td>\n      <td>-0.600491</td>\n      <td>0.548215</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>MI</th>\n      <td>6014</td>\n      <td>23110</td>\n      <td>-0.739766</td>\n      <td>-8.003398</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>MN</th>\n      <td>1664</td>\n      <td>8282</td>\n      <td>-0.799082</td>\n      <td>2.556019</td>\n      <td>0.010602</td>\n      <td>**</td>\n    </tr>\n    <tr>\n      <th>MO</th>\n      <td>1241</td>\n      <td>7184</td>\n      <td>-0.827255</td>\n      <td>-3.137250</td>\n      <td>0.001711</td>\n      <td>***</td>\n    </tr>\n    <tr>\n      <th>MS</th>\n      <td>88</td>\n      <td>1148</td>\n      <td>-0.923345</td>\n      <td>-0.697494</td>\n      <td>0.485625</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>MT</th>\n      <td>22</td>\n      <td>84</td>\n      <td>-0.738095</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>NC</th>\n      <td>756</td>\n      <td>14531</td>\n      <td>-0.947973</td>\n      <td>-5.059808</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>ND</th>\n      <td>16</td>\n      <td>115</td>\n      <td>-0.860870</td>\n      <td>0.221732</td>\n      <td>0.824873</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>NE</th>\n      <td>49</td>\n      <td>306</td>\n      <td>-0.839869</td>\n      <td>-3.127550</td>\n      <td>0.001909</td>\n      <td>***</td>\n    </tr>\n    <tr>\n      <th>NH</th>\n      <td>462</td>\n      <td>695</td>\n      <td>-0.335252</td>\n      <td>0.560195</td>\n      <td>0.575455</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>NJ</th>\n      <td>2249</td>\n      <td>28658</td>\n      <td>-0.921523</td>\n      <td>0.295288</td>\n      <td>0.767776</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>NM</th>\n      <td>91</td>\n      <td>743</td>\n      <td>-0.877524</td>\n      <td>2.185773</td>\n      <td>0.029110</td>\n      <td>**</td>\n    </tr>\n    <tr>\n      <th>NV</th>\n      <td>42</td>\n      <td>497</td>\n      <td>-0.915493</td>\n      <td>1.727083</td>\n      <td>0.084728</td>\n      <td>*</td>\n    </tr>\n    <tr>\n      <th>NY</th>\n      <td>18260</td>\n      <td>72025</td>\n      <td>-0.746477</td>\n      <td>-36.693141</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>OH</th>\n      <td>817</td>\n      <td>7278</td>\n      <td>-0.887744</td>\n      <td>4.203492</td>\n      <td>0.000027</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>OK</th>\n      <td>214</td>\n      <td>2360</td>\n      <td>-0.909322</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>PA</th>\n      <td>906</td>\n      <td>9045</td>\n      <td>-0.899834</td>\n      <td>-1.810339</td>\n      <td>0.070273</td>\n      <td>*</td>\n    </tr>\n    <tr>\n      <th>PR</th>\n      <td>139</td>\n      <td>1008</td>\n      <td>-0.862103</td>\n      <td>-2.964223</td>\n      <td>0.003097</td>\n      <td>***</td>\n    </tr>\n    <tr>\n      <th>RI</th>\n      <td>597</td>\n      <td>5083</td>\n      <td>-0.882550</td>\n      <td>-12.808389</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>SC</th>\n      <td>5</td>\n      <td>67</td>\n      <td>-0.925373</td>\n      <td>0.457800</td>\n      <td>0.648514</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>SD</th>\n      <td>21</td>\n      <td>477</td>\n      <td>-0.955975</td>\n      <td>-2.873357</td>\n      <td>0.004236</td>\n      <td>***</td>\n    </tr>\n    <tr>\n      <th>TN</th>\n      <td>1223</td>\n      <td>5828</td>\n      <td>-0.790151</td>\n      <td>0.415806</td>\n      <td>0.677564</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>TX</th>\n      <td>1789</td>\n      <td>5816</td>\n      <td>-0.692400</td>\n      <td>-17.924876</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>UT</th>\n      <td>1526</td>\n      <td>3032</td>\n      <td>-0.496702</td>\n      <td>-10.823623</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>VA</th>\n      <td>541</td>\n      <td>5823</td>\n      <td>-0.907093</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>VT</th>\n      <td>429</td>\n      <td>2687</td>\n      <td>-0.840342</td>\n      <td>-2.208600</td>\n      <td>0.027275</td>\n      <td>**</td>\n    </tr>\n    <tr>\n      <th>WI</th>\n      <td>587</td>\n      <td>5081</td>\n      <td>-0.884472</td>\n      <td>-6.132794</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n    <tr>\n      <th>WY</th>\n      <td>27</td>\n      <td>618</td>\n      <td>-0.956311</td>\n      <td>1.765108</td>\n      <td>0.078020</td>\n      <td>*</td>\n    </tr>\n    <tr>\n      <th>USA</th>\n      <td>85824</td>\n      <td>410383</td>\n      <td>-0.790869</td>\n      <td>-77.837711</td>\n      <td>0.000000</td>\n      <td>****</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Simplify dataset\n",
    "df_ttest = df2[['STFIPS', 'LIVARAG', 'METHUSE']]\n",
    "df_ttest = df_ttest[df_ttest['LIVARAG'] != 'Unknown']\n",
    "# df_ttest = df_ttest[df_ttest['LIVARAG'] != 'DependLiving']\n",
    "df_ttest['LIVARAG'] = df_ttest['LIVARAG'].replace({'DependLiving':'Housed', 'IndependentLiving':'Housed'})\n",
    "df_ttest['METHUSE'] = df_ttest['METHUSE'].replace({'MethUse':1, 'NoMethUse':0})\n",
    "\n",
    "# Create loop assets\n",
    "state_array = df_ttest['STFIPS'].sort_values().unique()\n",
    "state_list = state_array.tolist()\n",
    "state_list.append('USA')\n",
    "df_state = pd.DataFrame(columns=['Homeless', 'Housed', 'PercentDifference', 'TStat', 'PValue', 'Significance'])\n",
    "\n",
    "# Loop through each state\n",
    "for s in state_list:\n",
    "    # Define dataframe based on whether state or national\n",
    "    if s == 'USA':\n",
    "        dft_temp = df_ttest.copy()\n",
    "    else:\n",
    "        dft_temp = df_ttest[df_ttest['STFIPS'] == s]\n",
    "\n",
    "    # Group by living arrangement and MOUD, then store those variables for later (if they exist)\n",
    "    # dft_grouped = dft_temp.groupby('LIVARAG')['METHUSE'].mean()\n",
    "    # dft_grouped = dft_temp.groupby('LIVARAG')['METHUSE'].sum()\n",
    "    dft_grouped = dft_temp.groupby('LIVARAG')['METHUSE'].count()\n",
    "    homeless_moud = dft_grouped.loc['Homeless']\n",
    "    independent_moud = dft_grouped.loc['Housed']\n",
    "\n",
    "    # Calculate the percent difference (if there is a homeless group in that state)\n",
    "    if independent_moud > 0:\n",
    "       percent_difference = (homeless_moud - independent_moud)/independent_moud\n",
    "    # elif homeless_moud = 0:\n",
    "    #     percent_difference\n",
    "    else:\n",
    "        percent_difference = np.nan\n",
    "\n",
    "    # Perform a t-test between the two groups\n",
    "    group_A_values = dft_temp[dft_temp['LIVARAG'] == 'Homeless']['METHUSE']\n",
    "    group_B_values = dft_temp[dft_temp['LIVARAG'] == 'Housed']['METHUSE']\n",
    "    t_stat, p_value = ttest_ind(group_A_values, group_B_values)\n",
    "\n",
    "    # Add significance based on p-value\n",
    "    if p_value < 0.001:\n",
    "        significance = '****'\n",
    "    elif p_value < 0.01:\n",
    "        significance = '***'\n",
    "    elif p_value < 0.05:\n",
    "        significance = '**'\n",
    "    elif p_value <0.1:\n",
    "        significance = '*'\n",
    "    else:\n",
    "        significance = ''\n",
    "\n",
    "    # Add values to a dictionary and round\n",
    "    dict_results = {'Homeless':homeless_moud, 'Housed':independent_moud, 'PercentDifference':percent_difference, 'TStat':t_stat, 'PValue':p_value}\n",
    "    for key, value in dict_results.items():\n",
    "        dict_results[key] = round(value, 6)\n",
    "\n",
    "    # Add significance and to dictionary and then dictionary to dataframe\n",
    "    dict_results['Significance'] = significance\n",
    "    df_state.loc[s] = dict_results\n",
    "\n",
    "# df_state.to_csv('frequencies.csv') #uncomment to save file\n",
    "df_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}